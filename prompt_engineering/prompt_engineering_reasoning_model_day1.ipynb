{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Prompt with Reasoning Models (OpenAI & Claude)\n",
    "\n",
    "This notebook demonstrates how to effectively use reasoning models like **OpenAI's o3/o4-mini** and **Claude's Extended Thinking** for various tasks, including structured prompting, few-shot learning, and generating responses with specific policies. Below is a detailed guide to help students navigate and understand the notebook.\n",
    "\n",
    "## 1. Introduction\n",
    "This notebook is designed to teach students how to:\n",
    "* Load and configure API keys for reasoning models (OpenAI & Anthropic).\n",
    "* List available OpenAI models programmatically.\n",
    "* Apply best practices for prompting reasoning models.\n",
    "* Use structured formats and few-shot examples to improve model responses.\n",
    "* Compare different reasoning models (o3, o4-mini, o3-mini) and their costs.\n",
    "* Understand when to use reasoning models vs. regular models.\n",
    "* Leverage Claude's Extended Thinking feature for advanced reasoning.\n",
    "\n",
    "## 2. Prerequisites\n",
    "Before running the notebook, ensure the following:\n",
    "\n",
    "**Python Environment:** Install Python 3.8+.\n",
    "\n",
    "**Required Libraries:**\n",
    "- `openai` - For OpenAI API access\n",
    "- `anthropic` - For Claude API access\n",
    "- `python-dotenv` - For environment variable management\n",
    "- `IPython` - For enhanced display\n",
    "\n",
    "**API Keys:**\n",
    "Obtain API keys for OpenAI and Anthropic.\n",
    "Store them in a `.env` file in the same directory as the notebook:\n",
    "\n",
    "```bash\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "ANTHROPIC_API_KEY=your_anthropic_api_key\n",
    "```\n",
    "\n",
    "**Install dependencies:**\n",
    "```bash\n",
    "pip install openai anthropic python-dotenv ipython jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Sections\n",
    "\n",
    "## üìö Loading API Keys\n",
    "\n",
    "### Purpose\n",
    "Load API keys securely using the `dotenv` library to authenticate with OpenAI and other services.\n",
    "\n",
    "### Code Implementation\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Verify API keys are loaded successfully\n",
    "if openai_api_key:\n",
    "    print(\"‚úÖ OpenAI API key loaded successfully\")\n",
    "else:\n",
    "    print(\"‚ùå OpenAI API key not found\")\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(\"‚úÖ Anthropic API key loaded successfully\")  \n",
    "else:\n",
    "    print(\"‚ùå Anthropic API key not found\")\n",
    "```\n",
    "\n",
    "### Expected Output\n",
    "- Confirmation messages indicating whether API keys are successfully loaded\n",
    "- Security best practice: API key values are not displayed for privacy protection\n",
    "\n",
    "### Prerequisites\n",
    "- Create a `.env` file in your project root directory\n",
    "- Add your API keys in the format: `OPENAI_API_KEY=your_actual_key_here`\n",
    "- Install required dependencies: `pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Python Code:\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch API keys\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Check if API keys are loaded\n",
    "if openai_api_key and anthropic_api_key:\n",
    "    print(\"‚úÖ API keys are successfully loaded.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: One or more API keys are missing.\")\n",
    "\n",
    "# Optionally, display API keys (for debugging purposes only)\n",
    "display_keys = False  # Change to True if you want to see the keys\n",
    "\n",
    "if display_keys:\n",
    "    print(f\"OpenAI API Key: {openai_api_key}\")\n",
    "    print(f\"Anthropic API Key: {anthropic_api_key}\")\n",
    "else:\n",
    "    print(\"üîí API keys are loaded but hidden for security.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to List Available OpenAI Models via the API\n",
    "* You can programmatically retrieve the list of available models from OpenAI using their Python client. This is useful to check which models (e.g., gpt-5, gpt-5-mini, gpt-5-nano, gpt-4-turbo, gpt-3.5-turbo, etc.) are accessible to your API key and account.\n",
    "\n",
    "* Here‚Äôs how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (if using .env for API key)\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# List available models\n",
    "models = client.models.list()\n",
    "print(\"Available OpenAI Models:\")\n",
    "for model in models.data:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Initialize clients\n",
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "anthropic_client = Anthropic(api_key=anthropic_api_key)\n",
    "\n",
    "# OpenAI Models\n",
    "GPT_MODEL = 'gpt-4o'  # Regular model for comparison\n",
    "O3_MODEL = 'o3'  # Latest advanced reasoning model\n",
    "O4_MINI_MODEL = 'o4-mini'  # Cost-effective reasoning model\n",
    "O3_MINI_MODEL = 'o3-mini'  # Balanced reasoning model\n",
    "\n",
    "# Claude Models\n",
    "CLAUDE_OPUS = 'claude-opus-4-6'  # Most capable\n",
    "CLAUDE_SONNET = 'claude-sonnet-4-5-20250929'  # Balanced\n",
    "\n",
    "print(\"‚úÖ All models configured successfully!\")\n",
    "print(f\"üìä OpenAI Reasoning Models: {O3_MODEL}, {O4_MINI_MODEL}, {O3_MINI_MODEL}\")\n",
    "print(f\"üìä Claude Models: {CLAUDE_OPUS}, {CLAUDE_SONNET}\")\n",
    "print(f\"üìä Comparison Model: {GPT_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Principles on Prompting with Reasoning Models\n",
    "\n",
    "When working with reasoning models like o3, o4-mini, and Claude with Extended Thinking, follow these four key principles:\n",
    "\n",
    "## 1. Keep It Simple and Direct\n",
    "Reasoning models work best with clear, straightforward prompts. Avoid unnecessary complexity or verbose instructions.\n",
    "\n",
    "## 2. No Explicit Chain-of-Thought (CoT) Required\n",
    "**Do NOT** provide step-by-step instructions like \"Think through this step by step\" or \"Let's break this down\". \n",
    "\n",
    "Reasoning models have built-in reasoning capabilities. Adding explicit CoT instructions can:\n",
    "- Interfere with the model's internal reasoning process\n",
    "- Lead to overly verbose outputs\n",
    "- Cause inaccurate results or refusals\n",
    "\n",
    "‚ùå **Bad:** \"Think through this step by step, and don't skip any steps...\"\n",
    "‚úÖ **Good:** \"Generate a function that outputs the SMILES IDs for all the molecules involved in insulin.\"\n",
    "\n",
    "## 3. Use Structured Formats\n",
    "Leverage consistent structures like XML tags or markdown to organize your inputs:\n",
    "- Helps the model parse complex instructions\n",
    "- Ensures more uniform output\n",
    "- Improves reliability in production systems\n",
    "\n",
    "**Example:** Use `<instructions>`, `<policy>`, `<query>` tags to structure your prompts.\n",
    "\n",
    "## 4. Show Rather Than Tell (Few-Shot Learning)\n",
    "Instead of explaining what you want, provide 1-2 examples:\n",
    "- Demonstrates the desired format and style\n",
    "- Provides domain context naturally\n",
    "- Often more effective than lengthy instructions\n",
    "\n",
    "**Example:** Show an example of a legal response before asking for a similar analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_prompt = (\"Generate a function that outputs the SMILES IDs for all the molecules involved in insulin.\"\n",
    "              \"Think through this step by step, and don't skip any steps:\"\n",
    "              \"- Identify all the molecules involve in insulin\"\n",
    "              \"- Make the function\"\n",
    "              \"- Loop through each molecule, outputting each into the function and returning a SMILES ID\"\n",
    "              \"Molecules: \")\n",
    "\n",
    "try:\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=GPT_MODEL, \n",
    "        messages=[{\"role\":\"user\",\"content\": bad_prompt}]\n",
    "    )\n",
    "    print(f\"‚úÖ Response generated successfully with {GPT_MODEL}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "display(HTML('<div style=\"background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;\"></hr><h2>üîΩ &nbsp; Markdown Output ‚Äì Beginning</h2></hr></div>'))\n",
    "display(Markdown(response.choices[0].message.content))\n",
    "display(HTML('<div style=\"background-color: #fff4f4; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;\"></hr><h2>üîº &nbsp; Markdown Output ‚Äì End</h2></hr></div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_prompt = (\"Generate a function that outputs the SMILES IDs for all the molecules involved in insulin.\")\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=O3_MODEL, \n",
    "        messages=[{\"role\":\"user\",\"content\": good_prompt}]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Display metrics\n",
    "    print(f\"‚úÖ Response generated successfully with {O3_MODEL}\")\n",
    "    print(f\"‚è±Ô∏è Response time: {end_time - start_time:.2f}s\")\n",
    "    if hasattr(response.usage, 'reasoning_tokens'):\n",
    "        print(f\"üß† Reasoning tokens: {response.usage.reasoning_tokens}\")\n",
    "    print(f\"üìù Completion tokens: {response.usage.completion_tokens}\")\n",
    "    print(f\"üé´ Total tokens: {response.usage.total_tokens}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<div style=\"background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;\"></hr><h2>üîΩ &nbsp; Markdown Output ‚Äì Beginning</h2></hr></div>'))\n",
    "display(Markdown(response.choices[0].message.content))\n",
    "display(HTML('<div style=\"background-color: #fff4f4; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;\"></hr><h2>üîº &nbsp; Markdown Output ‚Äì End</h2></hr></div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Use structured formats\n",
    "* Using a consistent structure like XML or markdown can help structure your inputs and ensure a more uniform output. In this case we'll use a pseudo XML syntax to give consistent structure to our requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_prompt = (\"<instructions>You are a customer service assistant for AnyCorp, a provider\"\n",
    "          \"of fine storage solutions. Your role is to follow your policy to answer the user's question. \"\n",
    "          \"Be kind and respectful at all times.</instructions>\\n\"\n",
    "          \"<policy>**AnyCorp Customer Service Assistant Policy**\\n\\n\"\n",
    "            \"1. **Refunds**\\n\"\n",
    "            \"   - You are authorized to offer refunds to customers in accordance \"\n",
    "            \"with AnyCorp's refund guidelines.\\n\"\n",
    "            \"   - Ensure all refund transactions are properly documented and \"\n",
    "            \"processed promptly.\\n\\n\"\n",
    "            \"2. **Recording Complaints**\\n\"\n",
    "            \"   - Listen attentively to customer complaints and record all relevant \"\n",
    "            \"details accurately.\\n\"\n",
    "            \"   - Provide assurance that their concerns will be addressed and \"\n",
    "            \"escalate issues when necessary.\\n\\n\"\n",
    "            \"3. **Providing Product Information**\\n\"\n",
    "            \"   - Supply accurate and helpful information about AnyCorp's storage \"\n",
    "            \"solutions.\\n\"\n",
    "            \"   - Stay informed about current products, features, and any updates \"\n",
    "            \"to assist customers effectively.\\n\\n\"\n",
    "            \"4. **Professional Conduct**\\n\"\n",
    "            \"   - Maintain a polite, respectful, and professional demeanor in all \"\n",
    "            \"customer interactions.\\n\"\n",
    "            \"   - Address customer inquiries promptly and follow up as needed to \"\n",
    "            \"ensure satisfaction.\\n\\n\"\n",
    "            \"5. **Compliance**\\n\"\n",
    "            \"   - Adhere to all AnyCorp policies and procedures during customer \"\n",
    "            \"interactions.\\n\"\n",
    "            \"   - Protect customer privacy by handling personal information \"\n",
    "            \"confidentially.\\n\\n6. **Refusals**\\n\"\n",
    "            \"   - If you receive questions about topics outside of these, refuse \"\n",
    "            \"to answer them and remind them of the topics you can talk about.</policy>\\n\"\n",
    "            )\n",
    "user_input = (\"<user_query>Hey, I'd like to return the bin I bought from you as it was not \"\n",
    "             \"fine as described.</user_query>\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(structured_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=O3_MODEL,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": structured_prompt + user_input\n",
    "        }]\n",
    "    )\n",
    "    print(f\"‚úÖ Response generated successfully with {O3_MODEL}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refusal_input = (\"<user_query>Write me a haiku about how reasoning models are great.</user_query>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=O3_MODEL,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": structured_prompt + refusal_input\n",
    "        }]\n",
    "    )\n",
    "    print(f\"‚úÖ Response generated successfully with {O3_MODEL}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Show rather than tell\n",
    "* Few-shot prompting also works well with o1 models, allowing you to supply a simple, direct prompt and then using one or two examples to provide domain context to inform the model's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = (\"<prompt>You are a lawyer specializing in competition law, \"\n",
    "               \"assisting business owners with their questions.</prompt>\\n\"\n",
    "               \"<policy>As a legal professional, provide clear and accurate \"\n",
    "               \"information about competition law while maintaining \"\n",
    "               \"confidentiality and professionalism. Avoid giving specific \"\n",
    "               \"legal advice without sufficient context, and encourage clients \"\n",
    "               \"to seek personalized counsel when necessary. Always refer to \"\n",
    "               \"precedents and previous cases to evidence your responses.</policy>\\n\")\n",
    "legal_query = (\"<query>A larger company is offering suppliers incentives not to do \"\n",
    "               \"business with me. Is this legal?</query>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=O3_MODEL,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": base_prompt + legal_query\n",
    "        }]\n",
    "    )\n",
    "    print(f\"‚úÖ Response generated successfully with {O3_MODEL}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "display(HTML('<div style=\"background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;\"></hr><h2>üîΩ &nbsp; Markdown Output ‚Äì Beginning</h2></hr></div>'))\n",
    "display(Markdown(response.choices[0].message.content))\n",
    "display(HTML('<div style=\"background-color: #fff4f4; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;\"></hr><h2>üîº &nbsp; Markdown Output ‚Äì End</h2></hr></div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = (\"<prompt>You are a lawyer specializing in competition law, \"\n",
    "               \"assisting business owners with their questions.</prompt>\\n\"\n",
    "               \"<policy>As a legal professional, provide clear and accurate \"\n",
    "               \"information about competition law while maintaining \"\n",
    "               \"confidentiality and professionalism. Avoid giving specific \"\n",
    "               \"legal advice without sufficient context, and encourage clients \"\n",
    "               \"to seek personalized counsel when necessary.</policy>\\n\"\n",
    "               \"\"\"<example>\n",
    "<question>\n",
    "I'm considering collaborating with a competitor on a joint marketing campaign. Are there any antitrust issues I should be aware of?\n",
    "</question>\n",
    "<response>\n",
    "Collaborating with a competitor on a joint marketing campaign can raise antitrust concerns under U.S. antitrust laws, particularly the Sherman Antitrust Act of 1890 (15 U.S.C. ¬ß¬ß 1‚Äì7). Section 1 of the Sherman Act prohibits any contract, combination, or conspiracy that unreasonably restrains trade or commerce among the states.\n",
    "\n",
    "**Key Considerations:**\n",
    "\n",
    "1. **Per Se Illegal Agreements:** Certain collaborations are considered automatically illegal (\"per se\" violations), such as price-fixing, bid-rigging, and market allocation agreements. For example, in *United States v. Topco Associates, Inc.*, 405 U.S. 596 (1972), the Supreme Court held that market division agreements between competitors are per se illegal under the Sherman Act.\n",
    "\n",
    "2. **Rule of Reason Analysis:** Collaborations that are not per se illegal are evaluated under the \"rule of reason,\" which assesses whether the pro-competitive benefits outweigh the anti-competitive effects. In *Broadcast Music, Inc. v. Columbia Broadcasting System, Inc.*, 441 U.S. 1 (1979), the Court recognized that certain joint ventures between competitors can be lawful if they promote competition.\n",
    "\n",
    "3. **Information Sharing Risks:** Sharing competitively sensitive information, such as pricing strategies or customer data, can lead to antitrust violations. The Department of Justice and the Federal Trade Commission caution against exchanges that could facilitate collusion (*Antitrust Guidelines for Collaborations Among Competitors*, 2000).\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- **Define the Scope:** Clearly delineate the parameters of the collaboration to focus on the marketing campaign without involving competitive aspects like pricing or market division.\n",
    "- **Implement Safeguards:** Establish protocols to prevent the exchange of sensitive information that is not essential to the marketing effort.\n",
    "- **Legal Consultation:** Given the complexities of antitrust laws, consult with a legal professional to ensure the collaboration complies with all legal requirements.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "While joint marketing campaigns between competitors are not inherently illegal, they must be structured carefully to avoid antitrust pitfalls. Legal guidance is essential to navigate these issues and to design a collaboration that achieves your business objectives without violating antitrust laws.\n",
    "</response>\n",
    "</example>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=O3_MODEL,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": example_prompt + legal_query\n",
    "        }]\n",
    "    )\n",
    "    print(f\"‚úÖ Response generated successfully with {O3_MODEL}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<div style=\"background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;\"></hr><h2>üîΩ &nbsp; Markdown Output ‚Äì Beginning</h2></hr></div>'))\n",
    "display(Markdown(response.choices[0].message.content))\n",
    "display(HTML('<div style=\"background-color: #fff4f4; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;\"></hr><h2>üîº &nbsp; Markdown Output ‚Äì End</h2></hr></div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary & Best Practices\n",
    "\n",
    "## üéì Key Takeaways:\n",
    "\n",
    "1. **Keep prompts simple** - Let reasoning models figure out the steps\n",
    "2. **Don't provide explicit CoT** - It can interfere with internal reasoning\n",
    "3. **Use structured formats** - XML tags help organize complex requests\n",
    "4. **Show examples** - Few-shot learning works great with reasoning models\n",
    "5. **Choose the right model** - Consider task complexity, budget, and speed needs\n",
    "6. **Monitor costs** - Reasoning models are more expensive per token\n",
    "7. **Use Claude Extended Thinking** - When you need transparency in reasoning\n",
    "\n",
    "## üìö Further Learning:\n",
    "\n",
    "- **OpenAI Documentation**: https://platform.openai.com/docs/models\n",
    "- **Anthropic Documentation**: https://docs.anthropic.com/\n",
    "- **Prompt Engineering Guide**: https://www.promptingguide.ai/\n",
    "\n",
    "## üöÄ Next Steps:\n",
    "\n",
    "1. Try the interactive testing function with your own prompts\n",
    "2. Experiment with different models on the same task\n",
    "3. Compare cost vs. quality for your specific use case\n",
    "4. Practice with the 4 principles in real scenarios\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Reasoning! üß†‚ú®**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Your Own Prompt! (Interactive Example)\n",
    "\n",
    "# Uncomment and modify this to test with your own prompt:\n",
    "# test_reasoning_model(\n",
    "#     prompt=\"Your question here\",\n",
    "#     model_name=\"o3\",  # Options: 'o3', 'o4-mini', 'o3-mini', 'gpt-4o'\n",
    "#     display_metrics=True\n",
    "# )\n",
    "\n",
    "print(\"üí° Ready to test! Uncomment the code above and add your prompt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection Guide\n",
    "\n",
    "## ü§î Which Model Should I Use?\n",
    "\n",
    "### Decision Tree:\n",
    "\n",
    "```\n",
    "START: What's your task?\n",
    "‚îÇ\n",
    "‚îú‚îÄ Simple factual query? ‚Üí Use gpt-4o (regular model)\n",
    "‚îÇ\n",
    "‚îú‚îÄ Complex reasoning required?\n",
    "‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îú‚îÄ Budget is NOT a concern? ‚Üí Use o3 or Claude Opus\n",
    "‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îú‚îÄ Need cost-effective solution? ‚Üí Use o4-mini or o3-mini\n",
    "‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ Need transparency in reasoning? ‚Üí Use Claude with Extended Thinking\n",
    "‚îÇ\n",
    "‚îî‚îÄ Creative writing/generation? ‚Üí Use gpt-4o (reasoning not needed)\n",
    "```\n",
    "\n",
    "## ‚úÖ When TO Use Reasoning Models:\n",
    "\n",
    "1. **Complex Multi-Step Problems**\n",
    "   - Mathematical proofs\n",
    "   - Logic puzzles\n",
    "   - Strategic planning\n",
    "\n",
    "2. **Code Analysis & Debugging**\n",
    "   - Finding subtle bugs\n",
    "   - Analyzing complex algorithms\n",
    "   - Architecture decisions\n",
    "\n",
    "3. **Nuanced Decision Making**\n",
    "   - Ethical dilemmas\n",
    "   - Trade-off analysis\n",
    "   - Legal reasoning\n",
    "\n",
    "4. **Research & Analysis**\n",
    "   - Literature review\n",
    "   - Data interpretation\n",
    "   - Comparative analysis\n",
    "\n",
    "## ‚ùå When NOT to Use Reasoning Models:\n",
    "\n",
    "1. **Simple Tasks** - Overkill for basic queries\n",
    "2. **Creative Writing** - Regular models often better\n",
    "3. **Quick Responses Needed** - Reasoning models are slower\n",
    "4. **High-Volume Applications** - Cost adds up quickly\n",
    "5. **Straightforward Summarization** - Regular models sufficient\n",
    "\n",
    "## üí° Model-Specific Recommendations:\n",
    "\n",
    "### Use **o3** when:\n",
    "- Accuracy is critical\n",
    "- Problem requires deep reasoning\n",
    "- Budget allows ($15-60 per 1M tokens)\n",
    "- Examples: Medical diagnosis, legal analysis, complex math\n",
    "\n",
    "### Use **o4-mini / o3-mini** when:\n",
    "- Good reasoning needed at lower cost\n",
    "- Moderate complexity problems\n",
    "- High-volume applications\n",
    "- Examples: Customer support, code review, tutoring\n",
    "\n",
    "### Use **Claude Opus with Extended Thinking** when:\n",
    "- You need to see the reasoning process\n",
    "- Building AI systems that explain decisions\n",
    "- Educational purposes (showing how AI thinks)\n",
    "- Examples: AI safety research, transparent decision-making\n",
    "\n",
    "### Use **gpt-4o** (regular) when:\n",
    "- Speed matters more than reasoning depth\n",
    "- Simple factual questions\n",
    "- Creative tasks\n",
    "- General conversation\n",
    "- Examples: Chatbots, content generation, translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reasoning_model(prompt, model_name='o3', display_metrics=True):\n",
    "    \"\"\"\n",
    "    Test any reasoning model with your custom prompt\n",
    "    \n",
    "    Args:\n",
    "        prompt: Your question or task\n",
    "        model_name: 'o3', 'o4-mini', 'o3-mini', or 'gpt-4o'\n",
    "        display_metrics: Whether to show performance metrics\n",
    "    \"\"\"\n",
    "    model_map = {\n",
    "        'o3': O3_MODEL,\n",
    "        'o4-mini': O4_MINI_MODEL,\n",
    "        'o3-mini': O3_MINI_MODEL,\n",
    "        'gpt-4o': GPT_MODEL\n",
    "    }\n",
    "    \n",
    "    if model_name not in model_map:\n",
    "        print(f\"‚ùå Unknown model: {model_name}\")\n",
    "        print(f\"Available models: {list(model_map.keys())}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        print(f\"ü§ñ Testing with {model_name}...\\n\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model_map[model_name],\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_completion_tokens=2000\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        if display_metrics:\n",
    "            print(f\"‚è±Ô∏è Time: {end_time - start_time:.2f}s\")\n",
    "            print(f\"üé´ Tokens: {response.usage.total_tokens}\")\n",
    "            cost = calculate_cost(response.usage, model_map[model_name])\n",
    "            print(f\"üí∞ Cost: ${cost:.4f}\\n\")\n",
    "        \n",
    "        display(HTML(f'<div style=\"background-color: #f5f5f5; padding: 15px; border-radius: 5px; border-left: 4px solid #2196f3; margin: 10px 0;\"><h3>üéØ Response from {model_name}</h3></div>'))\n",
    "        display(Markdown(response.choices[0].message.content))\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Interactive testing function ready!\")\n",
    "print(\"\\nüìù Usage example:\")\n",
    "print('test_reasoning_model(\"Your prompt here\", model_name=\"o3\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Testing Function\n",
    "\n",
    "Now you can test your own prompts with any reasoning model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Multi-Step Planning\n",
    "\n",
    "planning_prompt = \"\"\"Plan a 3-day trip to Singapore with the following constraints:\n",
    "- Budget: $500 USD total\n",
    "- Interests: Technology, food, culture\n",
    "- Must visit at least 2 museums\n",
    "- Need to account for transportation between locations\n",
    "- Want to try at least 5 different local dishes\n",
    "\n",
    "Provide a detailed day-by-day itinerary with estimated costs.\"\"\"\n",
    "\n",
    "try:\n",
    "    print(\"üó∫Ô∏è Testing Multi-Step Planning with o4-mini...\\n\")\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=O4_MINI_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": planning_prompt}],\n",
    "        max_completion_tokens=1200\n",
    "    )\n",
    "    \n",
    "    display(HTML('<div style=\"background-color: #e0f7fa; padding: 15px; border-radius: 5px; margin: 10px 0;\"><h3>üèñÔ∏è Travel Itinerary</h3></div>'))\n",
    "    display(Markdown(response.choices[0].message.content))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Code Debugging\n",
    "\n",
    "debug_prompt = \"\"\"Find and explain the bug in this Python code:\n",
    "\n",
    "```python\n",
    "def find_duplicates(arr):\n",
    "    seen = {}\n",
    "    duplicates = []\n",
    "    for num in arr:\n",
    "        if seen[num]:\n",
    "            duplicates.append(num)\n",
    "        seen[num] = True\n",
    "    return duplicates\n",
    "\n",
    "# Test\n",
    "result = find_duplicates([1, 2, 3, 2, 4, 5, 3])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Explain what's wrong and provide the corrected code.\"\"\"\n",
    "\n",
    "try:\n",
    "    print(\"üêõ Testing Code Debugging with o3...\\n\")\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=O3_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": debug_prompt}],\n",
    "        max_completion_tokens=800\n",
    "    )\n",
    "    \n",
    "    display(HTML('<div style=\"background-color: #e8eaf6; padding: 15px; border-radius: 5px; margin: 10px 0;\"><h3>üîß Debugging Analysis</h3></div>'))\n",
    "    display(Markdown(response.choices[0].message.content))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Mathematical Proof\n",
    "\n",
    "math_prompt = \"\"\"Prove that the square root of 2 is irrational using proof by contradiction. \n",
    "Provide a complete, rigorous mathematical proof.\"\"\"\n",
    "\n",
    "try:\n",
    "    print(\"üßÆ Testing Mathematical Reasoning with o3...\\n\")\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=O3_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": math_prompt}],\n",
    "        max_completion_tokens=1000\n",
    "    )\n",
    "    \n",
    "    display(HTML('<div style=\"background-color: #f3e5f5; padding: 15px; border-radius: 5px; margin: 10px 0;\"><h3>üìê Mathematical Proof Result</h3></div>'))\n",
    "    display(Markdown(response.choices[0].message.content))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Reasoning Examples\n",
    "\n",
    "Let's test reasoning models with more complex, real-world scenarios that require multi-step thinking.\n",
    "\n",
    "## Example Categories:\n",
    "1. **Mathematical Proofs** - Formal reasoning with mathematics\n",
    "2. **Code Debugging** - Finding and explaining bugs\n",
    "3. **Multi-Step Planning** - Complex task decomposition\n",
    "4. **Ethical Dilemmas** - Nuanced reasoning about trade-offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Multiple Models on the Same Task\n",
    "\n",
    "test_prompt = \"Solve this logic puzzle: Five houses in a row are painted different colors. The green house is immediately to the left of the white house. The person in the green house drinks coffee. The person in the center house drinks milk. Who drinks water and in which house?\"\n",
    "\n",
    "models_to_test = [\n",
    "    ('o3', O3_MODEL, openai_client, 'openai'),\n",
    "    ('o4-mini', O4_MINI_MODEL, openai_client, 'openai'),\n",
    "    ('gpt-4o', GPT_MODEL, openai_client, 'openai')\n",
    "]\n",
    "\n",
    "print(\"üî¨ Running Model Comparison...\\n\")\n",
    "results = []\n",
    "\n",
    "for name, model, client, api_type in models_to_test:\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if api_type == 'openai':\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": test_prompt}],\n",
    "                max_completion_tokens=500\n",
    "            )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        cost = calculate_cost(response.usage, model)\n",
    "        \n",
    "        results.append({\n",
    "            'model': name,\n",
    "            'time': elapsed,\n",
    "            'tokens': response.usage.total_tokens,\n",
    "            'cost': cost,\n",
    "            'success': True\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ {name}: {elapsed:.2f}s | {response.usage.total_tokens} tokens | ${cost:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {name}: Error - {str(e)[:50]}...\")\n",
    "        results.append({\n",
    "            'model': name,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "print(\"\\nüìä Comparison complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost Calculator Function\n",
    "\n",
    "def calculate_cost(usage, model_name):\n",
    "    \"\"\"Calculate approximate cost for API call\"\"\"\n",
    "    # Pricing in dollars per 1M tokens (approximate)\n",
    "    pricing = {\n",
    "        'o3': {'input': 15.00, 'output': 60.00},\n",
    "        'o4-mini': {'input': 1.10, 'output': 4.40},\n",
    "        'o3-mini': {'input': 1.10, 'output': 4.40},\n",
    "        'gpt-4o': {'input': 2.50, 'output': 10.00},\n",
    "        'claude-opus-4-6': {'input': 15.00, 'output': 75.00},\n",
    "        'claude-sonnet-4-5-20250929': {'input': 3.00, 'output': 15.00}\n",
    "    }\n",
    "    \n",
    "    if model_name not in pricing:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    input_tokens = getattr(usage, 'input_tokens', 0) or getattr(usage, 'prompt_tokens', 0)\n",
    "    output_tokens = getattr(usage, 'output_tokens', 0) or getattr(usage, 'completion_tokens', 0)\n",
    "    \n",
    "    input_cost = (input_tokens / 1_000_000) * pricing[model_name]['input']\n",
    "    output_cost = (output_tokens / 1_000_000) * pricing[model_name]['output']\n",
    "    \n",
    "    return input_cost + output_cost\n",
    "\n",
    "print(\"‚úÖ Cost calculator function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison: Performance & Cost Analysis\n",
    "\n",
    "Let's compare different reasoning models across multiple dimensions:\n",
    "- **Response Quality**: How well does it solve complex problems?\n",
    "- **Speed**: Time to generate response\n",
    "- **Cost**: API pricing (approximate)\n",
    "- **Token Usage**: Input + output tokens\n",
    "\n",
    "## Pricing Reference (Approximate as of 2025):\n",
    "\n",
    "### OpenAI Models:\n",
    "| Model | Input (per 1M tokens) | Output (per 1M tokens) | Best For |\n",
    "|-------|----------------------|------------------------|----------|\n",
    "| o3 | $15.00 | $60.00 | Most complex reasoning |\n",
    "| o4-mini | $1.10 | $4.40 | Fast reasoning, budget-friendly |\n",
    "| o3-mini | $1.10 | $4.40 | Balanced reasoning |\n",
    "| gpt-4o | $2.50 | $10.00 | General tasks |\n",
    "\n",
    "### Claude Models:\n",
    "| Model | Input (per 1M tokens) | Output (per 1M tokens) | Extended Thinking |\n",
    "|-------|----------------------|------------------------|-------------------|\n",
    "| Claude Opus | $15.00 | $75.00 | Available |\n",
    "| Claude Sonnet | $3.00 | $15.00 | Available |\n",
    "\n",
    "**Note:** Prices may vary. Check official pricing pages for current rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Claude's Response with Thinking\n",
    "\n",
    "if 'response' in locals():\n",
    "    # Check if this is a Claude response (has .content as a list)\n",
    "    if hasattr(response, 'content') and isinstance(response.content, list):\n",
    "        display(HTML('<div style=\"background-color: #e8f5e9; padding: 15px; border-radius: 5px; border-left: 4px solid #4caf50; margin: 10px 0;\"><h3>üß† Claude\\'s Thinking Process & Response</h3></div>'))\n",
    "        \n",
    "        for i, block in enumerate(response.content):\n",
    "            if block.type == \"thinking\":\n",
    "                display(HTML('<div style=\"background-color: #fff3e0; padding: 10px; border-radius: 5px; margin: 5px 0;\"><strong>üí≠ Internal Reasoning:</strong></div>'))\n",
    "                display(Markdown(block.text))\n",
    "            elif block.type == \"text\":\n",
    "                display(HTML('<div style=\"background-color: #e3f2fd; padding: 10px; border-radius: 5px; margin: 5px 0;\"><strong>üí¨ Final Response:</strong></div>'))\n",
    "                display(Markdown(block.text))\n",
    "        \n",
    "        display(HTML('<div style=\"background-color: #fce4ec; padding: 10px; border-radius: 5px; margin: 10px 0;\"><strong>üîö End of Claude Response</strong></div>'))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è The 'response' variable contains an OpenAI response, not a Claude response.\")\n",
    "        print(\"‚ÑπÔ∏è  This cell is designed to display Claude's Extended Thinking output.\")\n",
    "        print(\"üìù Please run the Claude Extended Thinking cell (above) first.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No response to display. Run the Claude Extended Thinking cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Claude with Extended Thinking\n",
    "\n",
    "try:\n",
    "    print(f\"ü§ñ Testing Claude {CLAUDE_OPUS} with Extended Thinking...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=CLAUDE_OPUS,\n",
    "        max_tokens=4000,\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 2000\n",
    "        },\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": good_prompt\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Display metrics\n",
    "    print(f\"‚úÖ Response generated successfully\")\n",
    "    print(f\"‚è±Ô∏è Response time: {end_time - start_time:.2f}s\")\n",
    "    print(f\"üìù Total tokens: {response.usage.input_tokens + response.usage.output_tokens}\")\n",
    "    print(f\"\\nüìä Response Structure:\")\n",
    "    \n",
    "    # Claude's response may include thinking blocks\n",
    "    for block in response.content:\n",
    "        print(f\"  - {block.type}: {len(block.text) if hasattr(block, 'text') else 'N/A'} characters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error with Claude Extended Thinking: {e}\")\n",
    "    print(\"‚ÑπÔ∏è Note: Extended Thinking may not be available on all accounts or regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude's Extended Thinking Feature\n",
    "\n",
    "Claude doesn't have separate \"reasoning models\" like OpenAI's o-series. Instead, Claude offers an **Extended Thinking** feature that can be enabled on any Claude model (Opus or Sonnet).\n",
    "\n",
    "## How Extended Thinking Works:\n",
    "- You enable it by adding a `thinking` parameter\n",
    "- The model shows its reasoning process before the final answer\n",
    "- You can control the \"thinking budget\" (how many tokens to use for reasoning)\n",
    "- Best for complex problems requiring multi-step reasoning\n",
    "\n",
    "## When to Use Claude Extended Thinking:\n",
    "- Complex analytical tasks\n",
    "- Multi-step problem solving\n",
    "- When you need transparency in reasoning\n",
    "- Situations requiring careful deliberation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
