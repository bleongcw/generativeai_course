{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Article Retrieval Tool using Open AI\n",
    "\n",
    "This section defines a simple Python function, `get_article`, that uses the `wikipedia` Python package to search for and retrieve the content of a Wikipedia article based on a search term. This function will be used as a tool for the agent to fetch up-to-date information from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "def get_article(search_term: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve Wikipedia article content.\n",
    "\n",
    "    Args:\n",
    "        search_term: Search query for Wikipedia\n",
    "\n",
    "    Returns:\n",
    "        Article content or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not search_term or not search_term.strip():\n",
    "            return \"Error: Search term cannot be empty.\"\n",
    "\n",
    "        results = wikipedia.search(search_term)\n",
    "\n",
    "        if not results:\n",
    "            return f\"No Wikipedia articles found for '{search_term}'.\"\n",
    "\n",
    "        first_result = results[0]\n",
    "        page = wikipedia.page(first_result, auto_suggest=False)\n",
    "        return page.content\n",
    "\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"The search term '{search_term}' is ambiguous. Please be more specific. Options: {', '.join(e.options[:5])}\"\n",
    "\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return f\"No Wikipedia page found for '{search_term}'.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving article: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Fetching and Previewing Wikipedia Articles\n",
    "\n",
    "Here, we demonstrate how to use the `get_article` function to retrieve and preview the content of Wikipedia articles for various search terms, such as \"Avengers: Doomsday\", \"Nezha 2\", \"History of Malaysia\", and \"Iron Man\". Only a preview of the article content is printed for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = get_article(\"Avengers: Doomsday\")\n",
    "# print(article[:1000]) \n",
    "# article is very long, so let's just print a preview\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "article = get_article(\"Avengers: Doomsday\")\n",
    "html_content = f\"\"\"\n",
    "<div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 8px; border-left: 4px solid #007bff;\">\n",
    "    <h3 style=\"color: #007bff; margin-top: 0;\">Avengers: Doomsday Answer Preview</h3>\n",
    "    <p style=\"line-height: 1.6; text-align: justify;\">{article[:1000]}...</p>\n",
    "    <small style=\"color: #6c757d;\">(Showing first 1000 characters)</small>\n",
    "</div>\n",
    "\"\"\"\n",
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = get_article(\"Nezha 2\")\n",
    "print(article[:500]) # article is very long, so let's just print a preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = get_article(\"History of Malaysia\")\n",
    "print(article[:3000]) #article is super long so let's just print a preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = get_article(\"Iron Man\")\n",
    "print(article[:1000]) #article is super long so let's just print a preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Schema Definition for OpenAI Function Calling\n",
    "\n",
    "This cell defines a tool schema dictionary, `article_search_tool`, which describes the Wikipedia retrieval tool in a format compatible with OpenAI's function calling API. The schema includes:\n",
    "\n",
    "- **Tool type**: Specifies this as a \"function\" for OpenAI's API\n",
    "- **Function name**: Identifies the tool as \"get_article\"\n",
    "- **Description**: Explains the tool's purpose for retrieving Wikipedia articles\n",
    "- **Parameters**: Defines the input structure with required search terms\n",
    "- **Required fields**: Ensures proper parameter validation\n",
    "\n",
    "This schema enables GPT models to understand when and how to use the Wikipedia article retrieval functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_search_tool = {\n",
    "    \"type\": \"function\",  # This is required for OpenAI\n",
    "    \"function\": {\n",
    "        \"name\": \"get_article\",\n",
    "        \"description\": \"A tool to retrieve an up to date Wikipedia article.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"search_term\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The search term to find a wikipedia article by title\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"search_term\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tool_calls(response):\n",
    "    \"\"\"Extract tool calls from OpenAI response.\"\"\"\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        return response.choices[0].message.tool_calls\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up OpenAI Client and Making a Tool-Use Request\n",
    "\n",
    "This section initializes the OpenAI API client and demonstrates a complete tool-use workflow with GPT-4o. The implementation includes:\n",
    "\n",
    "- **Client Initialization**: Setting up the OpenAI client with proper authentication\n",
    "- **Tool Schema Definition**: Defining the Wikipedia article retrieval tool for OpenAI's function calling API\n",
    "- **Two-Stage API Calls**: First call to request tool use, second call to provide final answer\n",
    "- **Tool Execution**: Implementing the actual Wikipedia article retrieval functionality\n",
    "- **Beautiful Display**: Using IPython HTML to present results with professional styling\n",
    "\n",
    "The workflow handles questions that require external information (e.g., \"What is the box office for Nezha 2?\") by automatically detecting when tool use is needed, executing the Wikipedia search, and presenting the results in an elegant, formatted display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_tool_result(question: str, answer: str, tool_used: Optional[str] = None, search_term: Optional[str] = None) -> None:\n",
    "    \"\"\"Display AI response with beautiful HTML formatting.\"\"\"\n",
    "    html_content = f\"\"\"\n",
    "    <div style=\"font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; max-width: 800px; \n",
    "                margin: 20px auto; background: white; border-radius: 15px; \n",
    "                box-shadow: 0 10px 30px rgba(0,0,0,0.15); overflow: hidden;\">\n",
    "        <!-- Header -->\n",
    "        <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                    color: white; padding: 25px; text-align: center;\">\n",
    "            <h1 style=\"margin: 0; font-size: 24px;\">ü§ñ GPT-4o-mini Response</h1>\n",
    "            <p style=\"margin: 10px 0 0 0; opacity: 0.9;\">Powered by OpenAI with Tool Assistance</p>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Question -->\n",
    "        <div style=\"padding: 20px 25px 10px;\">\n",
    "            <h3 style=\"color: #2c3e50; margin: 0;\">‚ùì Question</h3>\n",
    "            <div style=\"background: #f8f9fa; padding: 15px; border-radius: 8px; \n",
    "                        margin-top: 10px; border-left: 4px solid #3498db;\">\n",
    "                <p style=\"margin: 0; font-size: 16px; color: #34495e;\">{question}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    if tool_used and search_term:\n",
    "        html_content += f\"\"\"\n",
    "        <div style=\"padding: 10px 25px;\">\n",
    "            <h3 style=\"color: #2c3e50; margin: 0;\">üîß Tool Used</h3>\n",
    "            <div style=\"background: #fff3cd; padding: 15px; border-radius: 8px; \n",
    "                        margin-top: 10px; border-left: 4px solid #f39c12;\">\n",
    "                <p style=\"margin: 0; font-weight: 600; color: #856404;\">\n",
    "                    <strong>Tool:</strong> {tool_used}<br>\n",
    "                    <strong>Search Term:</strong> {search_term}\n",
    "                </p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_content += f\"\"\"\n",
    "        <div style=\"padding: 10px 25px 25px;\">\n",
    "            <h3 style=\"color: #2c3e50; margin: 0;\">üí¨ Answer</h3>\n",
    "            <div style=\"background: #d4edda; padding: 20px; border-radius: 8px; \n",
    "                        margin-top: 10px; border-left: 4px solid #28a745;\">\n",
    "                <p style=\"margin: 0; font-size: 16px; line-height: 1.8; color: #155724; \n",
    "                           text-align: justify;\">{answer}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Footer -->\n",
    "        <div style=\"background: #2c3e50; color: white; padding: 15px 25px; \n",
    "                    text-align: center; font-size: 12px;\">\n",
    "            <p style=\"margin: 0;\">Generated with OpenAI GPT-4o-mini and IPython HTML Display</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Follow-up: Final Answer Generation\n",
    "\n",
    "This section sends the updated conversation (including the tool result) back to the model, prompting it to generate a final answer that incorporates the information retrieved from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "source": "# Initialize OpenAI client\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\nclient = OpenAI()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize messages with a clean state\nmessages = [{\"role\": \"user\", \"content\": \"What is the box office for Nezha 2\"}]\n\n# Now run the complete workflow with proper message structure\ntry:\n    # First API call\n    response = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=messages,\n        max_tokens=1000,\n        tools=[article_search_tool]\n    )\n    \n    # Handle tool calls with proper message structure\n    if response.choices[0].message.tool_calls:\n        # Add assistant's message with tool_calls FIRST\n        messages.append({\n            \"role\": \"assistant\",\n            \"content\": response.choices[0].message.content,\n            \"tool_calls\": response.choices[0].message.tool_calls\n        })\n        \n        # Execute tool\n        tool_call = response.choices[0].message.tool_calls[0]\n        tool_name = tool_call.function.name\n        tool_input = json.loads(tool_call.function.arguments)\n        \n        if tool_name == \"get_article\":\n            search_term = tool_input[\"search_term\"]\n            wiki_result = get_article(search_term)\n            \n            # Add tool response AFTER the assistant message\n            tool_response = {\n                \"role\": \"tool\",\n                \"tool_call_id\": tool_call.id,\n                \"content\": wiki_result\n            }\n            messages.append(tool_response)\n            \n            # Final API call (without tools parameter)\n            follow_up_response = client.chat.completions.create(\n                model=\"gpt-4o-mini\",\n                messages=messages,\n                max_tokens=1000\n            )\n            \n            # Get final answer\n            final_answer = follow_up_response.choices[0].message.content\n            print(\"Final Answer:\", final_answer)\n    \nexcept Exception as e:\n    print(f\"Error: {str(e)}\")\n    print(\"Messages at error:\", messages)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agentic Tool Use: Full Question-Answering Loop\n",
    "\n",
    "This cell defines a reusable function, `answer_question`, that demonstrates the full agentic tool-use loop: sending a question to the model, detecting tool use, executing the tool, sending the result, and printing the model's final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import wikipedia\n",
    "\n",
    "# Make sure client is initialized\n",
    "load_dotenv()\n",
    "if 'client' not in globals():\n",
    "    client = OpenAI()\n",
    "\n",
    "# Define the Wikipedia article retrieval function\n",
    "# Define the tool schema for OpenAI\n",
    "\n",
    "def answer_question(question):\n",
    "    \"\"\"\n",
    "    Answer a question using OpenAI GPT-4o with tool assistance\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "    \n",
    "    try:\n",
    "        # First API call\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_completion_tokens=1000,\n",
    "        \n",
    "        # Handle tool calls\n",
    "        if response.choices[0].message.tool_calls:\n",
    "            # Add assistant's message with tool_calls (must include the entire message object)\n",
    "            assistant_message = response.choices[0].message\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": assistant_message.content or \"\",  # Use empty string if content is None\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": tc.id,\n",
    "                        \"type\": tc.type,\n",
    "                        \"function\": {\n",
    "                            \"name\": tc.function.name,\n",
    "                            \"arguments\": tc.function.arguments\n",
    "                        }\n",
    "                    }\n",
    "                    for tc in assistant_message.tool_calls\n",
    "                ]\n",
    "            })\n",
    "            \n",
    "            # Execute ALL tool calls (not just the first one!)\n",
    "            for tool_call in response.choices[0].message.tool_calls:\n",
    "                tool_name = tool_call.function.name\n",
    "                tool_input = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                if tool_name == \"get_article\":\n",
    "                    search_term = tool_input[\"search_term\"]\n",
    "                    print(f\"üîç Searching Wikipedia for: {search_term}\")\n",
    "                    wiki_result = get_article(search_term)\n",
    "                    \n",
    "                    # Add tool response for THIS specific tool call\n",
    "                    tool_response = {\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"content\": wiki_result\n",
    "                    }\n",
    "                    messages.append(tool_response)\n",
    "                \n",
    "            # Final API call (after all tool responses are added)\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                max_completion_tokens=1000\n",
    "            )\n",
    "        \n",
    "        # Get final answer\n",
    "        final_answer = response.choices[0].message.content\n",
    "        return final_answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Now you can call it\n",
    "result = answer_question(\"What are the names of all the Avengers films that are confirmed in the Marvel Cinematic Universe?\")\n",
    "print(\"Answer:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_answer_with_html(question, answer):\n",
    "    \"\"\"\n",
    "    Display the question and answer with beautiful HTML styling\n",
    "    \"\"\"\n",
    "    html_content = f\"\"\"\n",
    "    <div style=\"\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "        max-width: 800px;\n",
    "        margin: 20px auto;\n",
    "        background: white;\n",
    "        border-radius: 15px;\n",
    "        box-shadow: 0 10px 30px rgba(0,0,0,0.15);\n",
    "        overflow: hidden;\n",
    "    \">\n",
    "        <!-- Header -->\n",
    "        <div style=\"\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            padding: 25px;\n",
    "            text-align: center;\n",
    "        \">\n",
    "            <h1 style=\"margin: 0; font-size: 24px;\">ü§ñ AI Response</h1>\n",
    "            <p style=\"margin: 10px 0 0 0; opacity: 0.9;\">Powered by GPT-4o with Tool Assistance</p>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Question -->\n",
    "        <div style=\"padding: 20px 25px 10px;\">\n",
    "            <h3 style=\"color: #2c3e50; margin: 0;\">‚ùì Question</h3>\n",
    "            <div style=\"\n",
    "                background: #f8f9fa;\n",
    "                padding: 15px;\n",
    "                border-radius: 8px;\n",
    "                margin-top: 10px;\n",
    "                border-left: 4px solid #3498db;\n",
    "            \">\n",
    "                <p style=\"margin: 0; font-size: 16px; color: #34495e;\">{question}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Answer -->\n",
    "        <div style=\"padding: 10px 25px 25px;\">\n",
    "            <h3 style=\"color: #2c3e50; margin: 0;\">üí¨ Answer</h3>\n",
    "            <div style=\"\n",
    "                background: #d4edda;\n",
    "                padding: 20px;\n",
    "                border-radius: 8px;\n",
    "                margin-top: 10px;\n",
    "                border-left: 4px solid #28a745;\n",
    "            \">\n",
    "                <p style=\"\n",
    "                    margin: 0; \n",
    "                    font-size: 16px; \n",
    "                    line-height: 1.8; \n",
    "                    color: #155724;\n",
    "                    text-align: justify;\n",
    "                \">{answer}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Footer -->\n",
    "        <div style=\"\n",
    "            background: #2c3e50;\n",
    "            color: white;\n",
    "            padding: 15px 25px;\n",
    "            text-align: center;\n",
    "            font-size: 12px;\n",
    "        \">\n",
    "            <p style=\"margin: 0;\">Generated with OpenAI GPT-4o and IPython HTML Display</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html_content))\n",
    "\n",
    "def answer_question(question):\n",
    "    \"\"\"\n",
    "    Answer a question using OpenAI GPT-4o with tool assistance\n",
    "    \"\"\"\n",
    "    # Start with a clean messages array\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "    \n",
    "    try:\n",
    "        # First API call\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=1000,\n",
    "            tools=[article_search_tool]\n",
    "        )\n",
    "        \n",
    "        # Handle tool calls\n",
    "        if response.choices[0].message.tool_calls:\n",
    "            # Add assistant's message with tool_calls\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response.choices[0].message.content,\n",
    "                \"tool_calls\": response.choices[0].message.tool_calls\n",
    "            })\n",
    "            \n",
    "            # Execute ALL tool calls (not just the first one)\n",
    "            for tool_call in response.choices[0].message.tool_calls:\n",
    "                tool_name = tool_call.function.name\n",
    "                tool_input = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                if tool_name == \"get_article\":\n",
    "                    search_term = tool_input[\"search_term\"]\n",
    "                    print(f\"üîç Searching Wikipedia for: {search_term}\")\n",
    "                    wiki_result = get_article(search_term)\n",
    "                    \n",
    "                    # Add tool response for THIS specific tool call\n",
    "                    tool_response = {\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,  # Use the specific tool_call.id\n",
    "                        \"content\": wiki_result\n",
    "                    }\n",
    "                    messages.append(tool_response)\n",
    "            \n",
    "            # Final API call\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                max_tokens=1000\n",
    "            )\n",
    "        \n",
    "        # Get final answer\n",
    "        final_answer = response.choices[0].message.content\n",
    "        \n",
    "        # Display with beautiful HTML\n",
    "        display_answer_with_html(question, final_answer)\n",
    "        \n",
    "        return final_answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error: {str(e)}\"\n",
    "        display_answer_with_html(question, error_msg)\n",
    "        return error_msg\n",
    "\n",
    "# Test the function with HTML display\n",
    "result = answer_question(\"What is quantum computing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: When No Tool is Needed\n",
    "\n",
    "This example demonstrates when Claude answers directly without using external tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question that doesn't require external data\n",
    "question = \"What is 2 + 2?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": question}],\n",
    "    max_tokens=500,\n",
    "    tools=[article_search_tool]\n",
    ")\n",
    "\n",
    "print(f\"Finish reason: {response.choices[0].finish_reason}\")\n",
    "print(f\"\\nGPT's response:\")\n",
    "if not response.choices[0].message.tool_calls:\n",
    "    print(\"‚úÖ Answered without tools:\")\n",
    "    print(response.choices[0].message.content)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Used a tool (unexpected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Turn Conversation with Tools\n",
    "\n",
    "Demonstrates handling multiple tool calls in a single conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-turn conversation example\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about the movie Nezha 2\"}\n",
    "]\n",
    "\n",
    "print(\"üîÑ Starting multi-turn conversation...\\n\")\n",
    "\n",
    "# First API call\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    max_tokens=1000,\n",
    "    tools=[article_search_tool]\n",
    ")\n",
    "\n",
    "# Handle tool use\n",
    "if response.choices[0].message.tool_calls:\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    tool_args = json.loads(tool_call.function.arguments)\n",
    "    \n",
    "    print(f\"üìö GPT wants to search: '{tool_args['search_term']}'\")\n",
    "    \n",
    "    # Add assistant's response (must include tool_calls)\n",
    "    messages.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": response.choices[0].message.content,\n",
    "        \"tool_calls\": [{\n",
    "            \"id\": tool_call.id,\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": tool_call.function.name,\n",
    "                \"arguments\": tool_call.function.arguments\n",
    "            }\n",
    "        }]\n",
    "    })\n",
    "    \n",
    "    # Execute tool\n",
    "    wiki_result = get_article(tool_args[\"search_term\"])\n",
    "    \n",
    "    # Add tool result\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"content\": wiki_result[:2000]  # Limit length\n",
    "    })\n",
    "    \n",
    "    # Get final response\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüí¨ GPT's answer:\")\n",
    "    print(response.choices[0].message.content[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Errors Gracefully\n",
    "\n",
    "Examples of how the robust error handling works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Non-existent article\n",
    "print(\"Test 1: Non-existent article\")\n",
    "result = get_article(\"xyzabc123notrealatall\")\n",
    "print(result[:200])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Ambiguous search (will show disambiguation options)\n",
    "print(\"Test 2: Ambiguous search term\")\n",
    "result = get_article(\"Mercury\")\n",
    "print(result[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Differences: OpenAI vs Anthropic Tool Use\n",
    "\n",
    "### Schema Format\n",
    "- **OpenAI**: Wraps in `type: \"function\"` with `parameters` field\n",
    "```python\n",
    "{\"type\": \"function\", \"function\": {\"name\": \"...\", \"parameters\": {...}}}\n",
    "```\n",
    "- **Anthropic**: Uses `input_schema` directly\n",
    "```python\n",
    "{\"name\": \"...\", \"description\": \"...\", \"input_schema\": {...}}\n",
    "```\n",
    "\n",
    "### Response Structure\n",
    "- **OpenAI**: `response.choices[0].message.tool_calls` is array or None\n",
    "- **Anthropic**: `response.content` is array of ContentBlocks\n",
    "\n",
    "### Tool Result Format\n",
    "- **OpenAI**: \n",
    "```python\n",
    "{\"role\": \"tool\", \"tool_call_id\": \"...\", \"content\": \"...\"}\n",
    "```\n",
    "- **Anthropic**: \n",
    "```python\n",
    "{\"role\": \"user\", \"content\": [{\"type\": \"tool_result\", ...}]}\n",
    "```\n",
    "\n",
    "### Finish/Stop Reasons\n",
    "- **OpenAI**: `\"tool_calls\"`, `\"stop\"`, `\"length\"`, `\"content_filter\"`\n",
    "- **Anthropic**: `\"tool_use\"`, `\"end_turn\"`, `\"max_tokens\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Summary & Next Steps\n",
    "\n",
    "### What You Learned\n",
    "- ‚úÖ How to define tools for OpenAI GPT models\n",
    "- ‚úÖ Complete agentic loop with function calling API\n",
    "- ‚úÖ Error handling for edge cases\n",
    "- ‚úÖ Multi-turn conversations with tools\n",
    "- ‚úÖ Security best practices (json.loads vs eval)\n",
    "\n",
    "### Best Practices\n",
    "1. **Always validate inputs** before calling tools\n",
    "2. **Use json.loads()** not eval() for parsing arguments\n",
    "3. **Handle errors gracefully** with try/except blocks\n",
    "4. **Use helper functions** (`extract_tool_calls`) for cleaner code\n",
    "5. **Display results beautifully** with HTML formatting\n",
    "\n",
    "### Resources\n",
    "- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)\n",
    "- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)\n",
    "- [GitHub Repository](https://github.com/bleongcw/generativeai_course)\n",
    "\n",
    "### Next Steps\n",
    "1. Try building your own tools (API calls, database queries, etc.)\n",
    "2. Experiment with multiple tools working together\n",
    "3. Add streaming for real-time responses\n",
    "4. Implement caching for frequently-used data\n",
    "5. Build a complete application using these patterns\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}