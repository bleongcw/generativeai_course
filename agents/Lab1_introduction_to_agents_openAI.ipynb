{
 "cells": [
  {
   "cell_type": "code",
   "id": "fdetdke6ace",
   "source": "# Final Cost Summary\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üéì LAB 1 COMPLETE: INTRODUCTION TO AI AGENTS\")\nprint(\"=\"*70)\n\ntracker.report()\n\nprint(\"\\nüìö You've completed a comprehensive journey through:\")\nprint(\"  ‚Ä¢ 10 phases of progressive learning\")\nprint(\"  ‚Ä¢ 95+ runnable code examples\")\nprint(\"  ‚Ä¢ Multiple production-ready patterns\")\nprint(\"  ‚Ä¢ Real-world use cases\")\nprint(\"\")\nprint(\"üöÄ You're now ready to build production AI agents!\")\nprint(\"\")\nprint(\"üí° Next Steps:\")\nprint(\"  1. Experiment with your own use cases\")\nprint(\"  2. Combine patterns for complex applications\")\nprint(\"  3. Deploy to production with confidence\")\nprint(\"  4. Explore advanced topics (Lab 2 coming soon!)\")\nprint(\"\")\nprint(\"üìñ Resources:\")\nprint(\"  ‚Ä¢ OpenAI Docs: https://platform.openai.com/docs\")\nprint(\"  ‚Ä¢ Agents SDK: https://github.com/openai/agents\")\nprint(\"  ‚Ä¢ Traces: https://platform.openai.com/traces\")\nprint(\"  ‚Ä¢ Community: https://community.openai.com\")\nprint(\"\")\nprint(\"=\"*70)\nprint(\"‚ú® Thank you for learning with us! ‚ú®\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0rw0noex9wdi",
   "source": "## üéâ Congratulations! Lab Complete!\n\n### What You've Mastered\n\n#### üéØ Fundamentals (Phases 1-4)\n- ‚úÖ GPT-5.2 and GPT-4o model selection\n- ‚úÖ Cost tracking and optimization\n- ‚úÖ Creating and running agents\n- ‚úÖ Custom function tools\n- ‚úÖ WebSearchTool integration\n- ‚úÖ Structured outputs with Pydantic\n- ‚úÖ Temperature and creativity control\n- ‚úÖ Instruction engineering\n\n#### üöÄ Advanced (Phases 5-7)\n- ‚úÖ Multi-agent systems and handoffs\n- ‚úÖ Triage and routing patterns\n- ‚úÖ Streaming responses\n- ‚úÖ Parallel execution\n- ‚úÖ Memory and context management\n- ‚úÖ RAG systems\n- ‚úÖ Data analysis pipelines\n- ‚úÖ Content generation workflows\n- ‚úÖ Customer support bots\n\n#### üí° Production (Phases 8-10)\n- ‚úÖ Self-reflection patterns\n- ‚úÖ Conditional routing\n- ‚úÖ Error handling and retries\n- ‚úÖ Testing frameworks\n- ‚úÖ Performance benchmarking\n- ‚úÖ A/B testing\n- ‚úÖ Production best practices\n- ‚úÖ Deployment checklist\n\n---\n\n### üìä Your Lab Statistics\n\nRun this cell for your complete cost summary:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "9hipo1055na",
   "source": "## Quick Reference Card\n\n### Agent Creation\n```python\nagent = Agent(\n    name=\"MyAgent\",\n    instructions=\"What the agent does\",\n    model=\"gpt-4o\",  # or gpt-5.2-chat-latest\n    tools=[tool1, tool2],\n    output_type=MyModel,\n    model_settings=ModelSettings(temperature=0.7)\n)\n```\n\n### Running Agents\n```python\n# Standard\nresult = await Runner.run(agent, \"query\")\n\n# Streaming\nasync for event in Runner.run_streamed(agent, \"query\"):\n    if event.type == \"content_delta\":\n        print(event.content)\n\n# With trace\nwith trace(\"Task Name\"):\n    result = await Runner.run(agent, \"query\")\n\n# Parallel\nresults = await asyncio.gather(\n    Runner.run(agent1, \"query1\"),\n    Runner.run(agent2, \"query2\")\n)\n```\n\n### Custom Tools\n```python\n@function_tool\ndef my_tool(param: str) -> str:\n    \"\"\"Tool description\"\"\"\n    return f\"Result: {param}\"\n```\n\n### Structured Outputs\n```python\nclass MyOutput(BaseModel):\n    field: str = Field(description=\"What this is\")\n\nagent = Agent(output_type=MyOutput, ...)\nresult = await Runner.run(agent, \"query\")\noutput = result.final_output  # MyOutput instance\n```\n\n### Model Selection Guide\n- **gpt-4o-mini**: Simple, fast, cheap\n- **gpt-4o**: General purpose, balanced\n- **gpt-5.2-chat-latest**: Fast GPT-5.2 (Instant)\n- **gpt-5.2**: Complex reasoning (Thinking)\n- **gpt-5.2-pro**: Maximum quality\n- **gpt-5.2-codex**: Coding tasks\n\n### Cost Tracking\n```python\ntracker.add_call(\"gpt-4o\", input_tokens, output_tokens)\ntracker.add_web_search(count)\ntracker.report()\n```",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "qfmobkf9cn",
   "source": "## Production Deployment Checklist\n\n### ‚úÖ Before Deployment\n\n#### 1. Cost Management\n- [ ] Set up cost tracking\n- [ ] Configure budget alerts\n- [ ] Use appropriate models per task\n- [ ] Implement caching where possible\n\n#### 2. Error Handling\n- [ ] Try/except blocks around agent calls\n- [ ] Retry logic with exponential backoff\n- [ ] Fallback agents for reliability\n- [ ] Graceful error messages\n\n#### 3. Performance\n- [ ] Benchmark response times\n- [ ] Use streaming for long tasks\n- [ ] Parallel execution where appropriate\n- [ ] Monitor and optimize\n\n#### 4. Quality\n- [ ] Test with diverse inputs\n- [ ] Validate structured outputs\n- [ ] Set temperature appropriately\n- [ ] Review agent instructions\n\n#### 5. Security\n- [ ] Validate user inputs\n- [ ] Sanitize tool parameters\n- [ ] Rate limiting\n- [ ] Authentication and authorization\n\n#### 6. Monitoring\n- [ ] Log all agent interactions\n- [ ] Track success/failure rates\n- [ ] Monitor costs\n- [ ] Alert on anomalies\n\n#### 7. Testing\n- [ ] Unit tests for individual agents\n- [ ] Integration tests for workflows\n- [ ] Load testing\n- [ ] A/B testing\n\n### üöÄ Deployment\n\n1. **Start Small**: Deploy to limited users\n2. **Monitor Closely**: Watch metrics\n3. **Iterate**: Improve based on feedback\n4. **Scale Gradually**: Expand as stable",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "aasnn2paz4n",
   "source": "## Common Pitfalls & Solutions\n\n### ‚ùå Pitfall 1: Tool Not Being Called\n**Problem**: Agent returns text instead of using tools\n\n**Solutions**:\n```python\n# Force tool use\nmodel_settings=ModelSettings(tool_choice=\"required\")\n\n# Clear instructions\ninstructions=\"You MUST use search_tool to find information\"\n\n# Verify tool is in tools list\ntools=[my_tool]\n```\n\n---\n\n### ‚ùå Pitfall 2: Infinite Loops\n**Problem**: Agent keeps calling tools without ending\n\n**Solution**:\n```python\n# Set max turns\nRunner.run(agent, query, max_turns=5)\n```\n\n---\n\n### ‚ùå Pitfall 3: High Costs\n**Problem**: Bills skyrocketing from expensive models\n\n**Solutions**:\n- Use gpt-4o-mini for simple tasks\n- Track costs with CostTracker\n- Set budget alerts\n- Cache responses\n- Optimize prompts\n\n---\n\n### ‚ùå Pitfall 4: Slow Responses\n**Problem**: Users waiting too long\n\n**Solutions**:\n```python\n# Use streaming\nRunner.run_streamed(agent, query)\n\n# Parallel execution\nasyncio.gather(task1, task2, task3)\n\n# Faster models\nmodel=\"gpt-4o-mini\"  # or gpt-5.2-chat-latest\n```\n\n---\n\n### ‚ùå Pitfall 5: Inconsistent Outputs\n**Problem**: Agent gives different answers each time\n\n**Solution**:\n```python\n# Lower temperature\nmodel_settings=ModelSettings(temperature=0.0)\n\n# Use structured outputs\noutput_type=MyPydanticModel\n```\n\n---\n\n### ‚ùå Pitfall 6: Context Loss\n**Problem**: Agent forgets conversation\n\n**Solution**:\n- Runner maintains context automatically\n- For long conversations, summarize periodically\n- Use RAG for persistent knowledge",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "ex9vtntpoib",
   "source": "## üìç PHASE 10: Best Practices & Summary\n\nFinal guidance for building production-ready AI agents.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "733zv5zvr8",
   "source": "## ‚úÖ Phase 9 Complete: Testing & Evaluation\n\n### What You Learned\n- ‚úÖ Agent testing framework with test cases\n- ‚úÖ Performance benchmarking (time, cost, quality)\n- ‚úÖ A/B testing different models\n- ‚úÖ Cost optimization strategies\n\n### Key Metrics\n1. **Performance**: Response time, throughput\n2. **Cost**: Token usage, $ per request\n3. **Quality**: Accuracy, relevance\n4. **Reliability**: Success rate, error handling\n\n### Testing Best Practices\n- Test with diverse inputs\n- Benchmark regularly\n- Track costs closely\n- A/B test changes\n- Automate testing\n\n### Optimization Tips\n- Use gpt-4o-mini for simple tasks (10x cheaper)\n- Reserve gpt-5.2-pro for critical work\n- Batch requests when possible\n- Cache common queries\n- Optimize prompts for clarity\n\n### Next Up: Phase 10 - Best Practices & Summary\nFinal checklist and production deployment guide!\n\n---\n\n**Final phase ahead!** ‚Üí Continue to Phase 10!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "sndx7joan8",
   "source": "# Cell 91: A/B Testing & Benchmarking\n\nclass BenchmarkResult(BaseModel):\n    agent_name: str\n    model: str\n    avg_time: float\n    avg_cost: float\n    output_length: int\n\nasync def benchmark_agent(agent, queries, model_name):\n    \"\"\"Benchmark an agent across multiple queries\"\"\"\n    \n    times = []\n    costs = []\n    lengths = []\n    \n    for query in queries:\n        start = time.time()\n        result = await Runner.run(agent, query)\n        elapsed = time.time() - start\n        \n        times.append(elapsed)\n        output = result.final_output\n        lengths.append(len(output))\n        \n        # Estimate cost (simplified)\n        input_tokens = len(query.split()) * 2\n        output_tokens = len(output.split()) * 2\n        cost = estimate_cost(model_name, input_tokens, output_tokens)\n        costs.append(cost)\n    \n    return BenchmarkResult(\n        agent_name=agent.name,\n        model=model_name,\n        avg_time=sum(times) / len(times),\n        avg_cost=sum(costs) / len(costs),\n        output_length=int(sum(lengths) / len(lengths))\n    )\n\nprint(\"‚ö° A/B Testing: GPT-4o vs GPT-4o-mini\\n\")\nprint(\"=\"*70)\n\n# Test queries\nqueries = [\n    \"Explain AI agents in 2 sentences\",\n    \"What is structured output?\",\n    \"Name 3 benefits of multi-agent systems\"\n]\n\n# Agent A: GPT-4o\nagent_a = Agent(\n    name=\"AgentA-GPT4o\",\n    instructions=\"Provide clear, concise answers\",\n    model=\"gpt-4o\"\n)\n\n# Agent B: GPT-4o-mini\nagent_b = Agent(\n    name=\"AgentB-GPT4o-mini\",\n    instructions=\"Provide clear, concise answers\",\n    model=\"gpt-4o-mini\"\n)\n\nprint(f\"\\nTesting with {len(queries)} queries...\\n\")\n\n# Benchmark both\nresult_a = await benchmark_agent(agent_a, queries, \"gpt-4o\")\nresult_b = await benchmark_agent(agent_b, queries, \"gpt-4o-mini\")\n\n# Track costs\ntracker.add_call(\"gpt-4o\", 150, 300)\ntracker.add_call(\"gpt-4o\", 150, 300)\ntracker.add_call(\"gpt-4o\", 150, 300)\ntracker.add_call(\"gpt-4o-mini\", 150, 300)\ntracker.add_call(\"gpt-4o-mini\", 150, 300)\ntracker.add_call(\"gpt-4o-mini\", 150, 300)\n\n# Display results\nprint(\"**Agent A (GPT-4o)**\")\nprint(f\"  Avg Time: {result_a.avg_time:.2f}s\")\nprint(f\"  Avg Cost: ${result_a.avg_cost:.6f}\")\nprint(f\"  Avg Length: {result_a.output_length} chars\")\n\nprint(\"\\n**Agent B (GPT-4o-mini)**\")\nprint(f\"  Avg Time: {result_b.avg_time:.2f}s\")\nprint(f\"  Avg Cost: ${result_b.avg_cost:.6f}\")\nprint(f\"  Avg Length: {result_b.output_length} chars\")\n\n# Comparison\nprint(\"\\n**Comparison**\")\ntime_diff = ((result_a.avg_time - result_b.avg_time) / result_b.avg_time) * 100\ncost_diff = ((result_b.avg_cost - result_a.avg_cost) / result_a.avg_cost) * 100\nprint(f\"  GPT-4o-mini is {abs(time_diff):.0f}% {'faster' if time_diff > 0 else 'slower'}\")\nprint(f\"  GPT-4o-mini is {abs(cost_diff):.0f}% cheaper\")\n\nprint(\"\\n\" + \"=\"*70)\ntracker.report()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fqwbroflsdu",
   "source": "## Performance Benchmarking & Cost Optimization\n\n### Benchmarking Metrics\n1. **Latency**: Response time\n2. **Throughput**: Requests per second\n3. **Cost**: $ per request\n4. **Quality**: Output accuracy/relevance\n\n### Cost Optimization Strategies\n- Use cheaper models for simple tasks (gpt-4o-mini)\n- Use expensive models only when needed (gpt-5.2-pro)\n- Batch similar requests\n- Cache common responses\n- Optimize prompts to reduce tokens\n- Use parallel execution wisely\n\n### A/B Testing\nCompare different approaches:\n- Model selection\n- Instruction variations\n- Temperature settings\n- Tool configurations",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "gt1ayi0yu7t",
   "source": "# Cell 89: Agent Testing Framework\n\nclass TestCase(BaseModel):\n    input: str = Field(description=\"Test input\")\n    expected_contains: List[str] = Field(description=\"Expected keywords in output\")\n    max_tokens: int = Field(description=\"Max expected tokens\")\n\nclass TestResult(BaseModel):\n    passed: bool\n    message: str\n    actual_output: str\n    execution_time: float\n\nasync def test_agent(agent, test_case: TestCase) -> TestResult:\n    \"\"\"Test an agent against a test case\"\"\"\n    \n    start = time.time()\n    \n    try:\n        result = await Runner.run(agent, test_case.input)\n        output = result.final_output\n        execution_time = time.time() - start\n        \n        # Check expected content\n        passed = all(\n            keyword.lower() in output.lower() \n            for keyword in test_case.expected_contains\n        )\n        \n        message = \"‚úÖ PASS\" if passed else \"‚ùå FAIL: Missing expected keywords\"\n        \n        return TestResult(\n            passed=passed,\n            message=message,\n            actual_output=output,\n            execution_time=execution_time\n        )\n    \n    except Exception as e:\n        return TestResult(\n            passed=False,\n            message=f\"‚ùå ERROR: {str(e)}\",\n            actual_output=\"\",\n            execution_time=time.time() - start\n        )\n\nprint(\"üß™ Agent Testing Framework\\n\")\nprint(\"=\"*70)\n\n# Test agent\ntest_agent_instance = Agent(\n    name=\"TestAgent\",\n    instructions=\"Answer questions accurately and concisely\",\n    model=\"gpt-4o\"\n)\n\n# Test cases\ntest_cases = [\n    TestCase(\n        input=\"What is an AI agent?\",\n        expected_contains=[\"agent\", \"autonomous\", \"AI\"],\n        max_tokens=500\n    ),\n    TestCase(\n        input=\"List 3 benefits of structured outputs\",\n        expected_contains=[\"1\", \"2\", \"3\", \"type\", \"valid\"],\n        max_tokens=300\n    ),\n]\n\n# Run tests\nresults = []\nfor i, test_case in enumerate(test_cases, 1):\n    print(f\"\\n**Test {i}**: {test_case.input}\")\n    result = await test_agent(test_agent_instance, test_case)\n    results.append(result)\n    \n    print(f\"{result.message}\")\n    print(f\"Time: {result.execution_time:.2f}s\")\n    print(f\"Output: {result.actual_output[:100]}...\")\n    \n    tracker.add_call(\"gpt-4o\", 100, 200)\n\n# Summary\nprint(\"\\n\" + \"=\"*70)\npassed = sum(1 for r in results if r.passed)\nprint(f\"\\nüìä Test Summary: {passed}/{len(results)} passed\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "xqaksqzhln8",
   "source": "## üìç PHASE 9: Testing & Evaluation\n\nEnsure your agents work correctly and meet quality standards.\n\n### Testing Strategies\n1. **Unit Tests**: Test individual agents\n2. **Integration Tests**: Test agent interactions\n3. **Performance Tests**: Measure speed and cost\n4. **Quality Tests**: Evaluate output quality\n\n### Metrics to Track\n- Response time\n- Token usage and cost\n- Success rate\n- Output quality\n- Error rate",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "8u76zqc1433",
   "source": "## ‚úÖ Phase 8 Complete: Advanced Patterns\n\n### What You Learned\n- ‚úÖ Self-reflection pattern (create ‚Üí critique ‚Üí improve)\n- ‚úÖ Conditional routing based on query analysis\n- ‚úÖ Error handling with try/except\n- ‚úÖ Retry logic with exponential backoff\n- ‚úÖ Fallback strategies for reliability\n\n### Production Patterns\n1. **Self-Reflection**: Iterative quality improvement\n2. **Routing**: Optimal agent selection\n3. **Error Handling**: Graceful failure management\n4. **Retries**: Automatic recovery\n5. **Fallbacks**: Secondary options\n\n### Key Takeaways\n- Production agents need robust error handling\n- Self-reflection improves output quality\n- Dynamic routing optimizes cost and performance\n- Always have fallback strategies\n\n### Next Up: Phase 9 - Testing & Evaluation\nLearn to test and benchmark your agents:\n- Testing framework\n- Performance benchmarking\n- Cost optimization\n- Quality evaluation\n\n---\n\n**Almost done!** ‚Üí Continue to Phase 9!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "jjka2qax33r",
   "source": "# Cell 86: Error Handling Demo\n\nasync def run_agent_with_retry(agent, query, max_retries=3):\n    \"\"\"Run agent with automatic retry logic\"\"\"\n    \n    for attempt in range(max_retries):\n        try:\n            result = await Runner.run(agent, query)\n            return result\n        \n        except Exception as e:\n            print(f\"‚ö†Ô∏è  Attempt {attempt + 1} failed: {type(e).__name__}\")\n            \n            if attempt < max_retries - 1:\n                wait_time = 2 ** attempt  # Exponential backoff\n                print(f\"   Retrying in {wait_time}s...\")\n                await asyncio.sleep(wait_time)\n            else:\n                print(f\"‚ùå All {max_retries} attempts failed\")\n                return None\n\n# Fallback pattern\nasync def run_agent_with_fallback(primary_agent, fallback_agent, query):\n    \"\"\"Try primary agent, fallback to secondary on failure\"\"\"\n    \n    try:\n        print(\"Trying primary agent...\")\n        result = await Runner.run(primary_agent, query)\n        return result\n    \n    except Exception as e:\n        print(f\"‚ö†Ô∏è  Primary failed: {type(e).__name__}\")\n        print(\"Falling back to secondary agent...\")\n        \n        try:\n            result = await Runner.run(fallback_agent, query)\n            return result\n        except Exception as e2:\n            print(f\"‚ùå Fallback also failed: {type(e2).__name__}\")\n            return None\n\nprint(\"üõ°Ô∏è Error Handling Demo\\n\")\nprint(\"=\"*70)\n\n# Demo agent\nreliable_agent = Agent(\n    name=\"ReliableAgent\",\n    instructions=\"Answer questions reliably\",\n    model=\"gpt-4o\"\n)\n\n# Simulate retry\nprint(\"\\n**Pattern 1: Retry with Backoff**\")\nquery = \"What are error handling best practices?\"\nresult = await run_agent_with_retry(reliable_agent, query, max_retries=3)\nif result:\n    print(f\"‚úÖ Success: {result.final_output[:150]}...\")\n    tracker.add_call(\"gpt-4o\", 100, 200)\n\n# Fallback pattern demo\nprint(\"\\n\" + \"=\"*70)\nprint(\"\\n**Pattern 2: Fallback Strategy**\")\nprint(\"Primary agent: GPT-4o\")\nprint(\"Fallback agent: GPT-4o-mini\")\n\nprimary = Agent(name=\"Primary\", instructions=\"Answer detailed\", model=\"gpt-4o\")\nfallback = Agent(name=\"Fallback\", instructions=\"Answer brief\", model=\"gpt-4o-mini\")\n\nresult = await run_agent_with_fallback(primary, fallback, query)\nif result:\n    print(f\"‚úÖ Got response from {result.agent.name}\")\n    tracker.add_call(\"gpt-4o\", 100, 200)\n\nprint(\"\\n\" + \"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fvpo2nk9i67",
   "source": "## Error Handling & Retry Logic\n\nRobust error handling for production agent systems.\n\n### Error Types\n1. **API Errors**: Rate limits, timeouts, auth issues\n2. **Tool Failures**: External service down\n3. **Validation Errors**: Bad structured output\n4. **Logic Errors**: Incorrect agent behavior\n\n### Strategies\n\n#### Try/Except Pattern\n```python\ntry:\n    result = await Runner.run(agent, query)\nexcept Exception as e:\n    # Fallback behavior\n    result = default_response\n```\n\n#### Retry with Exponential Backoff\n```python\nfor attempt in range(max_retries):\n    try:\n        result = await Runner.run(agent, query)\n        break\n    except RateLimitError:\n        wait_time = 2 ** attempt  # 1s, 2s, 4s, 8s...\n        await asyncio.sleep(wait_time)\n```\n\n### Best Practices\n- Always handle exceptions\n- Provide fallback responses\n- Log errors for debugging\n- Set reasonable retry limits\n- Use exponential backoff",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "wk4wjpibrds",
   "source": "# Cell 84: Conditional Routing\n\nclass QueryAnalysis(BaseModel):\n    intent: str = Field(description=\"User intent: question/task/research\")\n    complexity: str = Field(description=\"simple/medium/complex\")\n    domain: str = Field(description=\"Subject area\")\n    recommended_agent: str = Field(description=\"FastAgent or DeepThinkingAgent\")\n\n# Analyzer\nanalyzer_agent = Agent(\n    name=\"QueryAnalyzer\",\n    instructions=\"\"\"Analyze queries:\n- Intent: question/task/research\n- Complexity: simple/medium/complex\n- Domain: technical/general/creative\n\nRecommend:\n- FastAgent: simple questions, quick facts\n- DeepThinkingAgent: complex analysis, multi-step tasks\"\"\",\n    model=\"gpt-4o\",\n    output_type=QueryAnalysis\n)\n\n# Fast agent (low cost)\nfast_agent = Agent(\n    name=\"FastAgent\",\n    instructions=\"Provide quick, concise answers\",\n    model=\"gpt-4o-mini\"  # Cheaper model\n)\n\n# Deep thinking agent\ndeep_agent = Agent(\n    name=\"DeepThinkingAgent\",\n    instructions=\"Provide detailed analysis with reasoning and examples\",\n    model=\"gpt-4o\",  # More capable\n    model_settings=ModelSettings(temperature=0.3)\n)\n\nprint(\"üéØ Conditional Routing Demo\\n\")\nprint(\"=\"*70)\n\nqueries = [\n    \"What's 2+2?\",\n    \"Analyze the trade-offs between microservices and monolithic architecture\",\n    \"What time is it?\"\n]\n\nfor query in queries:\n    print(f\"\\n‚ùì Query: {query}\")\n    \n    # Analyze\n    analysis_result = await Runner.run(analyzer_agent, f\"Analyze: {query}\")\n    analysis = analysis_result.final_output\n    print(f\"‚Üí Complexity: {analysis.complexity}, Route to: {analysis.recommended_agent}\")\n    tracker.add_call(\"gpt-4o\", 80, 100)\n    \n    # Route\n    agent = fast_agent if \"Fast\" in analysis.recommended_agent else deep_agent\n    result = await Runner.run(agent, query)\n    print(f\"üí¨ {agent.name}: {result.final_output[:150]}...\")\n    \n    # Track appropriate cost\n    if agent == fast_agent:\n        tracker.add_call(\"gpt-4o-mini\", 50, 100)\n    else:\n        tracker.add_call(\"gpt-4o\", 150, 300)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ Routed queries to optimal agents!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fuckouqjrde",
   "source": "## Conditional Routing Pattern\n\nDynamic agent selection based on query analysis and context.\n\n### Pattern\n```\nQuery ‚Üí Analyzer ‚Üí Route to Best Agent ‚Üí Response\n```\n\n### Strategies\n1. **Intent-based**: Route by user intent\n2. **Complexity-based**: Route by difficulty\n3. **Domain-based**: Route by subject area\n4. **Confidence-based**: Route by certainty\n\n### Benefits\n- Optimal resource usage\n- Better responses\n- Cost optimization\n- Specialized handling",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "j604lh044r",
   "source": "# Cell 82: Self-Reflection Pattern\n\nclass Critique(BaseModel):\n    issues: List[str] = Field(description=\"Problems found\")\n    severity: str = Field(description=\"low/medium/high\")\n    suggestions: List[str] = Field(description=\"Improvements\")\n    score: int = Field(description=\"Quality score 1-10\")\n\n# Creator agent\ncreator_agent = Agent(\n    name=\"Creator\",\n    instructions=\"Write clear, concise explanations of technical concepts\",\n    model=\"gpt-4o\"\n)\n\n# Critic agent\ncritic_agent = Agent(\n    name=\"Critic\",\n    instructions=\"\"\"Critically analyze content for:\n- Clarity and readability\n- Technical accuracy\n- Completeness\n- Examples and evidence\n\nBe constructively critical.\"\"\",\n    model=\"gpt-4o\",\n    output_type=Critique\n)\n\n# Improver agent\nimprover_agent = Agent(\n    name=\"Improver\",\n    instructions=\"Improve content based on critique while preserving core message\",\n    model=\"gpt-4o\"\n)\n\nprint(\"üîÑ Self-Reflection Pattern\\n\")\nprint(\"=\"*70)\n\ntopic = \"Explain how agents use structured outputs\"\nmax_iterations = 2\n\n# Initial creation\nprint(f\"\\n**Topic**: {topic}\\n\")\nprint(\"**Iteration 1: Initial Creation**\")\nresult = await Runner.run(creator_agent, topic)\ncontent = result.final_output\nprint(f\"Created: {content[:200]}...\")\ntracker.add_call(\"gpt-4o\", 100, 300)\n\n# Iterative improvement\nfor i in range(max_iterations):\n    print(f\"\\n**Iteration {i+2}: Critique & Improve**\")\n    \n    # Critique\n    critique_result = await Runner.run(critic_agent, f\"Critique:\\n\\n{content}\")\n    critique = critique_result.final_output\n    print(f\"Score: {critique.score}/10\")\n    print(f\"Issues: {len(critique.issues)}\")\n    tracker.add_call(\"gpt-4o\", 400, 200)\n    \n    # Stop if good enough\n    if critique.score >= 8:\n        print(\"‚úÖ Quality threshold met!\")\n        break\n    \n    # Improve\n    improve_prompt = f\"\"\"Original:\\n{content}\\n\\nCritique:\\n{critique.model_dump_json()}\\n\\nImprove the content.\"\"\"\n    result = await Runner.run(improver_agent, improve_prompt)\n    content = result.final_output\n    print(f\"Improved: {content[:200]}...\")\n    tracker.add_call(\"gpt-4o\", 600, 350)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"**Final Output:**\")\nprint(content)\nprint(\"\\n\" + \"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "93bk31i1u9i",
   "source": "## Self-Reflection Pattern\n\nAgents that critique and improve their own work through iterative refinement.\n\n### Workflow\n```\nCreate ‚Üí Critique ‚Üí Improve ‚Üí Repeat\n```\n\n### Benefits\n- ‚úÖ Higher quality outputs\n- ‚úÖ Self-correction of errors\n- ‚úÖ Iterative improvement\n- ‚úÖ Reduced human review\n\n### Pattern\n1. **Creator**: Generates initial output\n2. **Critic**: Analyzes and finds flaws\n3. **Improver**: Refines based on critique\n4. **Repeat**: Until quality threshold met\n\n### Use Cases\n- Code generation and review\n- Content creation\n- Research reports\n- Complex problem solving",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "vg7muqd7x1j",
   "source": "## üìç PHASE 8: Advanced Patterns\n\nProduction-ready patterns for robust agent systems:\n\n### Patterns Covered\n1. **Self-Reflection**: Agents critique and improve their own outputs\n2. **Conditional Routing**: Dynamic agent selection based on context\n3. **Error Handling**: Graceful failure management\n4. **Retry Logic**: Automatic recovery from failures\n\nThese patterns make agents more reliable and production-ready.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "xtf8qzbvjtf",
   "source": "## ‚úÖ Phase 7 Complete: Real-World Use Cases\n\n### What You Learned\n- ‚úÖ RAG systems with knowledge retrieval\n- ‚úÖ Data analysis pipelines with structured outputs\n- ‚úÖ Content generation workflows (research ‚Üí outline ‚Üí write ‚Üí edit)\n- ‚úÖ Customer support bots with triage routing\n\n### Production Patterns\n1. **RAG**: Combine retrieval with reasoning\n2. **Pipelines**: Chain specialized agents\n3. **Content**: Multi-stage quality control\n4. **Support**: Automatic triage and routing\n\n### Key Takeaways\n- Break complex tasks into stages\n- Use appropriate models per stage\n- Structured outputs for parsing\n- Handoffs for specialization\n\n### Real-World Applications\nThese patterns can be adapted for:\n- Documentation systems\n- Research assistants\n- Content platforms\n- Customer service\n- Data analytics\n- Code review\n- And much more!\n\n### Next Up: Phase 8 - Advanced Patterns\nLearn production-ready patterns:\n- Self-reflection and improvement\n- Conditional routing\n- Error handling strategies\n- Retry logic\n\n---\n\n**Ready for advanced patterns?** ‚Üí Continue to Phase 8!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "dnodjlq4iua",
   "source": "# Cell 78: Customer Support Bot\n\n# Specialized support agents\ntechnical_support = Agent(\n    name=\"TechnicalSupport\",\n    instructions=\"\"\"You are a technical support specialist.\n\nHelp with:\n- API errors and troubleshooting\n- Integration issues\n- Code examples\n- Best practices\n\nAlways provide specific solutions with examples.\"\"\",\n    model=\"gpt-4o\"\n)\n\nbilling_support = Agent(\n    name=\"BillingSupport\",\n    instructions=\"\"\"You are a billing support specialist.\n\nHelp with:\n- Payment issues\n- Subscription changes\n- Refund requests\n- Invoice questions\n\nBe empathetic and solution-oriented.\"\"\",\n    model=\"gpt-4o\"\n)\n\ngeneral_support = Agent(\n    name=\"GeneralSupport\",\n    instructions=\"\"\"You are a general support agent.\n\nHelp with:\n- Product information\n- Getting started\n- Feature questions\n- General inquiries\n\nBe friendly and informative.\"\"\",\n    model=\"gpt-4o\"\n)\n\n# Triage router\ntriage_agent = Agent(\n    name=\"TriageAgent\",\n    instructions=\"\"\"You route customer queries to the right specialist:\n\n- Technical issues (errors, API, code) ‚Üí TechnicalSupport\n- Billing/account/payment ‚Üí BillingSupport\n- General questions ‚Üí GeneralSupport\n\nRoute immediately without answering the query yourself.\"\"\",\n    model=\"gpt-4o\",\n    handoff_to=[\"TechnicalSupport\", \"BillingSupport\", \"GeneralSupport\"]\n)\n\nprint(\"üéß Customer Support Bot\\n\")\nprint(\"=\"*70)\n\n# Simulate customer queries\nqueries = [\n    \"I'm getting a 401 error when calling the API\",\n    \"How do I upgrade my subscription?\",\n    \"What features are included in the pro plan?\"\n]\n\nfor query in queries:\n    print(f\"\\nüë§ Customer: {query}\")\n    with trace(f\"Support: {query[:40]}\"):\n        result = await Runner.run(triage_agent, query)\n        print(f\"ü§ñ Support: {result.final_output[:300]}...\")\n    tracker.add_call(\"gpt-4o\", 150, 250)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ Support bot routed queries to appropriate specialists!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dmmnkuj6kus",
   "source": "## Customer Support Bot\n\nIntelligent support system with triage and specialized agents.\n\n### Architecture\n```\nCustomer Query ‚Üí Triage ‚Üí Technical / Billing / General\n```\n\n### Components\n1. **Triage**: Classifies query type\n2. **Technical Support**: Handles technical issues\n3. **Billing Support**: Handles account/payment\n4. **General Support**: Handles other questions\n\n### Features\n- Automatic routing\n- Specialized responses\n- Escalation handling\n- Context preservation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "th6hxzjuvto",
   "source": "# Cell 76: Content Generation Workflow\n\nprint(\"‚úçÔ∏è Content Generation Pipeline\\n\")\nprint(\"=\"*70)\n\ntopic = \"Best Practices for AI Agent Development\"\n\n# Stage 1: Research (with web search if available, otherwise synthesize)\nprint(\"\\nüìñ Stage 1: Research\")\nresearcher = Agent(\n    name=\"Researcher\",\n    instructions=\"Research the topic and provide key points, trends, and examples\",\n    model=\"gpt-4o\"\n)\n\nresearch_result = await Runner.run(researcher, f\"Research: {topic}\")\nresearch = research_result.final_output\nprint(f\"‚úì Gathered {len(research)} chars of research\")\ntracker.add_call(\"gpt-4o\", 100, 600)\n\n# Stage 2: Outline\nprint(\"\\nüìù Stage 2: Outline\")\n\nclass ArticleOutline(BaseModel):\n    title: str = Field(description=\"Engaging article title\")\n    hook: str = Field(description=\"Attention-grabbing opening\")\n    sections: List[str] = Field(description=\"Section headings\")\n    conclusion: str = Field(description=\"Closing summary\")\n\noutliner = Agent(\n    name=\"Outliner\",\n    instructions=\"Create a compelling article outline with clear structure\",\n    model=\"gpt-4o\",\n    output_type=ArticleOutline\n)\n\noutline_result = await Runner.run(\n    outliner,\n    f\"Create outline for: {topic}\\n\\nResearch:\\n{research[:1000]}\"\n)\noutline = outline_result.final_output\nprint(f\"‚úì Title: {outline.title}\")\nprint(f\"‚úì Sections: {len(outline.sections)}\")\ntracker.add_call(\"gpt-4o\", 800, 250)\n\n# Stage 3: Write\nprint(\"\\n‚úçÔ∏è  Stage 3: Writing\")\nwriter = Agent(\n    name=\"Writer\",\n    instructions=\"Write engaging, professional content following the outline\",\n    model=\"gpt-4o\",\n    model_settings=ModelSettings(temperature=0.8)\n)\n\ndraft_result = await Runner.run(\n    writer,\n    f\"Write article:\\n\\nTitle: {outline.title}\\n\\nSections: {outline.sections}\\n\\nResearch: {research[:800]}\"\n)\ndraft = draft_result.final_output\nprint(f\"‚úì Drafted {len(draft)} chars\")\ntracker.add_call(\"gpt-4o\", 1000, 800)\n\n# Stage 4: Edit\nprint(\"\\n‚úÇÔ∏è  Stage 4: Editing\")\n\nclass FinalArticle(BaseModel):\n    final_text: str = Field(description=\"Polished article\")\n    improvements: List[str] = Field(description=\"Changes made\")\n    word_count: int = Field(description=\"Final word count\")\n\neditor = Agent(\n    name=\"Editor\",\n    instructions=\"Polish for clarity, grammar, and flow. Improve readability.\",\n    model=\"gpt-4o\",\n    output_type=FinalArticle\n)\n\nfinal_result = await Runner.run(editor, f\"Edit:\\n\\n{draft[:1500]}\")\narticle = final_result.final_output\nprint(f\"‚úì Final: {article.word_count} words\")\nprint(f\"‚úì Improvements: {len(article.improvements)}\")\ntracker.add_call(\"gpt-4o\", 1500, 600)\n\n# Display results\nprint(\"\\n\" + \"=\"*70)\nprint(\"üìÑ FINAL ARTICLE\\n\")\nprint(f\"**{outline.title}**\\n\")\nprint(article.final_text[:500] + \"...\\n\")\nprint(f\"**Word Count**: {article.word_count}\")\nprint(f\"\\n**Editor's Improvements**:\")\nfor imp in article.improvements[:3]:\n    print(f\"  ‚Ä¢ {imp}\")\n\nprint(\"\\n\" + \"=\"*70)\ntracker.report()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "chvydplr3ji",
   "source": "## Content Generation Workflow\n\nEnd-to-end content creation using specialized agents.\n\n### Pipeline\n```\nResearch ‚Üí Outline ‚Üí Draft ‚Üí Edit ‚Üí Final\n```\n\n### Agents\n1. **Researcher**: Gathers information\n2. **Outliner**: Creates structure\n3. **Writer**: Generates content\n4. **Editor**: Polishes and refines\n\n### Benefits\n- Consistent quality\n- Scalable production\n- Different models per stage\n- Quality control at each step",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "736hfkrilnl",
   "source": "# Cell 74: Data Analysis Pipeline\n\n# Sample data\nsales_data = \"\"\"\nWeek 1: 1200 units, $48,000 revenue\nWeek 2: 1450 units, $58,000 revenue  \nWeek 3: 1100 units, $44,000 revenue\nWeek 4: 1800 units, $72,000 revenue\n\"\"\"\n\nclass AnalysisReport(BaseModel):\n    summary: str = Field(description=\"Executive summary\")\n    key_metrics: Dict[str, str] = Field(description=\"Important metrics\")\n    trends: List[str] = Field(description=\"Identified trends\")\n    insights: List[str] = Field(description=\"Business insights\")\n    recommendations: List[str] = Field(description=\"Action items\")\n\n# Data analysis agent\nanalyst_agent = Agent(\n    name=\"DataAnalyst\",\n    instructions=\"\"\"You are a data analyst. Analyze the provided data and generate:\n    \n1. Summary statistics (average, total, growth rate)\n2. Trends (increasing, decreasing, patterns)\n3. Business insights (what this means)\n4. Recommendations (what to do)\n\nBe specific with numbers and percentages.\"\"\",\n    model=\"gpt-4o\",\n    output_type=AnalysisReport\n)\n\nprint(\"üìä Data Analysis Pipeline\\n\")\nprint(\"=\"*70)\n\nprint(\"\\n**Input Data:**\")\nprint(sales_data)\n\nprint(\"\\n**Running analysis...**\\n\")\n\nwith trace(\"Data Analysis\"):\n    result = await Runner.run(analyst_agent, f\"Analyze this sales data:\\n\\n{sales_data}\")\n    report = result.final_output\n\n# Display structured report\nprint(\"**ANALYSIS REPORT**\\n\")\nprint(f\"**Summary**\\n{report.summary}\\n\")\n\nprint(\"**Key Metrics**\")\nfor metric, value in report.key_metrics.items():\n    print(f\"  ‚Ä¢ {metric}: {value}\")\n\nprint(\"\\n**Trends**\")\nfor trend in report.trends:\n    print(f\"  ‚Ä¢ {trend}\")\n\nprint(\"\\n**Insights**\")\nfor insight in report.insights:\n    print(f\"  ‚Ä¢ {insight}\")\n\nprint(\"\\n**Recommendations**\")\nfor rec in report.recommendations:\n    print(f\"  ‚Ä¢ {rec}\")\n\nprint(\"\\n\" + \"=\"*70)\ntracker.add_call(\"gpt-4o\", 250, 400)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "53sp3tndqa9",
   "source": "## Data Analysis Pipeline\n\nMulti-step data analysis using agent orchestration.\n\n### Workflow\n```\nRaw Data ‚Üí Analyzer ‚Üí Insights ‚Üí Visualizer ‚Üí Report\n```\n\n### Use Cases\n- Business intelligence\n- Research analysis\n- Performance monitoring\n- A/B test analysis\n\n### Pattern\n1. **Analyzer**: Processes raw data\n2. **Statistician**: Runs calculations\n3. **Insights**: Generates findings\n4. **Reporter**: Creates final report",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "5zpwofba647",
   "source": "# Cell 72: Simulated RAG System\n\n# Simulated knowledge base\nknowledge_base = {\n    \"agents_intro\": \"AI agents are autonomous software programs that use LLMs to make decisions and take actions.\",\n    \"agents_tools\": \"Agents can use tools like web search, calculators, and custom functions to extend their capabilities.\",\n    \"agents_structured\": \"Structured outputs use Pydantic models to ensure agents return typed, validated data.\",\n    \"agents_multiagent\": \"Multi-agent systems use multiple specialized agents working together via handoffs.\",\n    \"agents_cost\": \"GPT-4o costs $2.5/1M input tokens and $10/1M output tokens. WebSearchTool costs $0.025 per call.\"\n}\n\n@function_tool\ndef search_knowledge_base(query: str) -> str:\n    \"\"\"Search the knowledge base for relevant information\"\"\"\n    query_lower = query.lower()\n    \n    # Simple keyword matching (in production, use vector similarity)\n    results = []\n    for key, content in knowledge_base.items():\n        if any(word in content.lower() for word in query_lower.split()):\n            results.append(f\"[{key}]: {content}\")\n    \n    if results:\n        return \"\\\\n\\\\n\".join(results)\n    else:\n        return \"No relevant information found in knowledge base.\"\n\n# RAG agent\nrag_agent = Agent(\n    name=\"RAGAgent\",\n    instructions=\"\"\"You are a helpful assistant with access to a knowledge base.\n\nWhen answering:\n1. Use search_knowledge_base to find relevant information\n2. Cite sources from the knowledge base\n3. If information isn't in KB, say so clearly\n4. Combine multiple sources if needed\"\"\",\n    model=\"gpt-4o\",\n    tools=[search_knowledge_base],\n    model_settings=ModelSettings(tool_choice=\"required\")\n)\n\nprint(\"üìö RAG System Demo\\n\")\nprint(\"=\"*70)\n\nqueries = [\n    \"What are AI agents?\",\n    \"How much does GPT-4o cost?\",\n    \"Tell me about multi-agent systems\"\n]\n\nfor query in queries:\n    print(f\"\\n‚ùì Query: {query}\")\n    result = await Runner.run(rag_agent, query)\n    print(f\"üí¨ Answer: {result.final_output}\\n\")\n    tracker.add_call(\"gpt-4o\", 150, 200)\n\nprint(\"=\"*70)\nprint(\"‚úÖ RAG system answered queries using knowledge base!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5418151665v",
   "source": "## RAG System (Retrieval-Augmented Generation)\n\n**RAG** combines agent reasoning with knowledge retrieval from a database.\n\n### Architecture\n```\nUser Query\n    ‚Üì\nRetrieve Relevant Docs ‚Üí Agent (with context) ‚Üí Response\n```\n\n### Benefits\n- ‚úÖ Up-to-date information\n- ‚úÖ Source attribution\n- ‚úÖ Reduced hallucination\n- ‚úÖ Domain-specific knowledge\n\n### Implementation Pattern\n1. Build knowledge base (vector store)\n2. Query retrieves relevant chunks\n3. Agent reasons over retrieved context\n4. Response includes sources\n\n### Tools\n- **Vector DBs**: Pinecone, Weaviate, ChromaDB\n- **OpenAI**: FileSearchTool (built-in)\n- **Custom**: Build your own retrieval",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "0go2yxwk12dt",
   "source": "## üìç PHASE 7: Real-World Use Cases\n\nNow let's build practical production applications with AI agents:\n\n### Use Cases Covered\n1. **RAG System**: Knowledge base with retrieval\n2. **Data Analysis Pipeline**: Multi-step analysis workflow\n3. **Content Generation**: Research ‚Üí Outline ‚Üí Write ‚Üí Edit\n4. **Customer Support Bot**: Triage and specialized agents\n\nThese patterns can be adapted to your specific needs.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "8qj0uq3p03d",
   "source": "## ‚úÖ Phase 6 Complete: Advanced Features\n\n### What You Learned\n- ‚úÖ Advanced ModelSettings (temperature, max_tokens, parallel_tool_calls)\n- ‚úÖ Streaming responses for real-time output\n- ‚úÖ Memory and context management\n- ‚úÖ Multi-turn conversations\n- ‚úÖ Parallel agent execution with asyncio.gather()\n\n### Key Takeaways\n1. **ModelSettings**: Fine-tune behavior with temperature, token limits\n2. **Streaming**: Use `Runner.run_streamed()` for better UX\n3. **Memory**: Agents maintain conversation history automatically\n4. **Parallel**: Execute independent tasks simultaneously for speed\n\n### Production Tips\n- Stream long-running tasks\n- Monitor context window usage\n- Use parallel execution for independent tasks\n- Track costs across all parallel calls\n\n### Next Up: Phase 7 - Real-World Use Cases\nBuild practical applications:\n- RAG systems with knowledge bases\n- Data analysis pipelines\n- Content generation workflows\n- Customer support bots\n\n---\n\n**Ready for real-world applications?** ‚Üí Continue to Phase 7!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "s105supixv",
   "source": "# Cell 68: Parallel Execution Demo\n\nprint(\"‚ö° Parallel Agent Execution\\n\")\nprint(\"=\"*70)\n\ntopic = \"AI agent frameworks\"\n\n# Create 3 different agents\nsummary_agent = Agent(\n    name=\"Summarizer\",\n    instructions=\"Provide brief 2-sentence summaries\",\n    model=\"gpt-4o\"\n)\n\ndetail_agent = Agent(\n    name=\"Detailer\",\n    instructions=\"Provide detailed analysis with examples\",\n    model=\"gpt-4o\"\n)\n\ncritique_agent = Agent(\n    name=\"Critic\",\n    instructions=\"Provide critical analysis of limitations and challenges\",\n    model=\"gpt-4o\"\n)\n\n# Run all 3 agents in parallel\nprint(f\"\\nTopic: {topic}\")\nprint(\"\\nRunning 3 agents in parallel...\\n\")\n\nstart_time = time.time()\n\nresults = await asyncio.gather(\n    Runner.run(summary_agent, f\"Summarize: {topic}\"),\n    Runner.run(detail_agent, f\"Analyze in detail: {topic}\"),\n    Runner.run(critique_agent, f\"Critique: {topic}\"),\n    return_exceptions=True\n)\n\nelapsed = time.time() - start_time\n\n# Display results\nprint(f\"**Summary** (from Summarizer):\")\nprint(results[0].final_output if not isinstance(results[0], Exception) else \"Error\")\n\nprint(f\"\\n**Detailed Analysis** (from Detailer):\")\nprint(results[1].final_output[:300] if not isinstance(results[1], Exception) else \"Error\")\nprint(\"...\" if len(results[1].final_output) > 300 else \"\")\n\nprint(f\"\\n**Critical Analysis** (from Critic):\")\nprint(results[2].final_output[:300] if not isinstance(results[2], Exception) else \"Error\")\nprint(\"...\" if len(results[2].final_output) > 300 else \"\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(f\"‚è±Ô∏è  Completed in {elapsed:.2f}s (vs ~{elapsed*3:.2f}s if sequential)\")\n\ntracker.add_call(\"gpt-4o\", 150, 300)  # Per agent\ntracker.add_call(\"gpt-4o\", 150, 600)\ntracker.add_call(\"gpt-4o\", 150, 400)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "msfrxq1jaq",
   "source": "## Parallel Agent Execution\n\nExecute multiple agents simultaneously using `asyncio.gather()` for improved performance.\n\n### When to Use Parallel Execution\n- ‚úÖ Independent tasks (no dependencies)\n- ‚úÖ Research from multiple sources\n- ‚úÖ A/B testing different approaches\n- ‚úÖ Gathering diverse perspectives\n\n### Pattern\n\n```python\n# Define multiple agents\nagent1 = Agent(name=\"Agent1\", ...)\nagent2 = Agent(name=\"Agent2\", ...)\n\n# Run in parallel\nresults = await asyncio.gather(\n    Runner.run(agent1, \"task1\"),\n    Runner.run(agent2, \"task2\"),\n    return_exceptions=True  # Don't fail if one errors\n)\n```\n\n### Benefits\n- ‚ö° Faster: N tasks in ~same time as 1\n- üí™ Efficiency: Maximize API utilization\n- üéØ Redundancy: Multiple approaches simultaneously\n\n### Trade-offs\n- üí∞ Higher cost (multiple API calls)\n- üîÄ More complex error handling\n- ‚ö†Ô∏è Rate limits may apply",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "9taiqfpkmqw",
   "source": "# Cell 66: Multi-Turn Conversation Demo\n\nprint(\"üí¨ Multi-Turn Conversation Demo\\n\")\nprint(\"=\"*70)\n\nmemory_agent = Agent(\n    name=\"ConversationAgent\",\n    instructions=\"Have natural conversations, remembering previous context\",\n    model=\"gpt-4o\"\n)\n\n# Turn 1\nprint(\"\\n**Turn 1**\")\nquery1 = \"My favorite color is blue\"\nprint(f\"User: {query1}\")\nresult1 = await Runner.run(memory_agent, query1)\nprint(f\"Agent: {result1.final_output}\")\n\n# Turn 2 - Agent should remember color\nprint(\"\\n**Turn 2**\")\nquery2 = \"What's my favorite color?\"\nprint(f\"User: {query2}\")\nresult2 = await Runner.run(memory_agent, query2)\nprint(f\"Agent: {result2.final_output}\")\n\n# Turn 3 - Context preserved\nprint(\"\\n**Turn 3**\")\nquery3 = \"Name 3 things that are that color\"\nprint(f\"User: {query3}\")\nresult3 = await Runner.run(memory_agent, query3)\nprint(f\"Agent: {result3.final_output}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ Agent maintained context across turns!\")\n\ntracker.add_call(\"gpt-4o\", 300, 450)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "xopkeqgvn9q",
   "source": "## Memory & Context Management\n\nAgents maintain conversation history through **context**, enabling multi-turn interactions.\n\n### How Context Works\n1. User sends initial message\n2. Agent responds\n3. Previous messages stored in context\n4. Next message includes full history\n5. Agent has memory of conversation\n\n### Multi-Turn Pattern\n\n```python\n# First interaction\nresult1 = await Runner.run(agent, \"What's 5 + 3?\")\n\n# Second interaction (remembers first)\nresult2 = await Runner.run(agent, \"Multiply that by 2\")\n\n# Agent knows \"that\" refers to 8\n```\n\n### Context Window Limits\n- **GPT-5.2**: 400K tokens (~300K words)\n- **GPT-4o**: 128K tokens (~96K words)\n- **Best Practice**: Summarize long conversations\n\n### Memory Strategies\n1. **Short conversations**: Keep full history\n2. **Long conversations**: Summarize periodically\n3. **RAG pattern**: Store in vector database\n4. **Session management**: Clear context when changing topics",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "h0n24l7td6",
   "source": "# Cell 64: Streaming Demo\n\nprint(\"üì° Streaming Response Demo\\n\")\nprint(\"=\"*70)\n\nstreaming_agent = Agent(\n    name=\"StreamingWriter\",\n    instructions=\"Write detailed explanations with examples\",\n    model=\"gpt-4o\"\n)\n\nquery = \"Explain how AI agents use tools in 3 paragraphs\"\nprint(f\"\\nQuery: {query}\\n\")\nprint(\"Response (streaming):\\n\")\n\n# Stream the response\nasync for event in Runner.run_streamed(streaming_agent, query):\n    if event.type == \"content_delta\":\n        print(event.content, end=\"\", flush=True)\n    elif event.type == \"final\":\n        final_result = event.content\n\nprint(\"\\n\\n\" + \"=\"*70)\nprint(\"‚úÖ Streaming complete!\")\n\ntracker.add_call(\"gpt-4o\", 150, 400)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "oq56vt5hh4",
   "source": "## Streaming Responses\n\n**Streaming** provides real-time output as the agent generates responses, improving UX for long-running tasks.\n\n### Benefits\n- ‚úÖ Immediate feedback to users\n- ‚úÖ Better perceived performance\n- ‚úÖ Progress visibility\n- ‚úÖ Early cancellation if needed\n\n### How to Stream\n\n```python\n# Use Runner.run_streamed() instead of Runner.run()\nasync for event in Runner.run_streamed(agent, \"query\"):\n    if event.type == \"content_delta\":\n        print(event.content, end=\"\", flush=True)\n    elif event.type == \"final\":\n        result = event.content\n```\n\n### Event Types\n- `content_delta`: Incremental content chunks\n- `tool_call`: Agent called a tool\n- `tool_result`: Tool execution result\n- `final`: Complete response\n\n### Use Cases\n- Long research tasks\n- Content generation\n- Complex analysis\n- Interactive applications",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "kn4f9tbt0bl",
   "source": "# Cell 62: ModelSettings Demo\n\nprint(\"‚öôÔ∏è ModelSettings Comparison\\n\")\nprint(\"=\"*70)\n\ntask = \"Calculate: (234 * 567) + 891\"\n\n# Settings 1: Low temperature, fast\nfast_agent = Agent(\n    name=\"FastCalculator\",\n    instructions=\"Solve math problems step by step\",\n    model=\"gpt-4o\",\n    model_settings=ModelSettings(\n        temperature=0.0,      # Deterministic\n        max_tokens=500       # Limit output\n    )\n)\n\nprint(\"\\n**Settings 1**: temperature=0.0, max_tokens=500\")\nresult1 = await Runner.run(fast_agent, task)\nprint(result1.final_output)\n\n# Settings 2: Parallel tool execution\nmulti_tool_agent = Agent(\n    name=\"ParallelToolUser\",\n    instructions=\"Get time and calculate cost\",\n    model=\"gpt-4o\",\n    tools=[get_current_time, calculate_cost],\n    model_settings=ModelSettings(\n        parallel_tool_calls=True,  # Run tools concurrently\n        tool_choice=\"required\"\n    )\n)\n\nprint(\"\\n**Settings 2**: parallel_tool_calls=True\")\nresult2 = await Runner.run(\n    multi_tool_agent, \n    \"What time is it? Also calculate cost for 500 input and 1000 output tokens with gpt-4o\"\n)\nprint(result2.final_output)\n\ntracker.add_call(\"gpt-4o\", 200, 400)\nprint(\"\\n\" + \"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3pmlhw4nhsn",
   "source": "## Advanced ModelSettings\n\n**ModelSettings** provides fine-grained control over agent behavior:\n\n```python\nModelSettings(\n    temperature=0.7,           # 0.0-2.0: Creativity control\n    max_tokens=4096,          # Max output tokens\n    parallel_tool_calls=True, # Run tools concurrently\n    tool_choice=\"auto\",       # \"auto\", \"required\", \"none\"\n    top_p=1.0,               # Nucleus sampling\n)\n```\n\n### Key Parameters\n\n| Parameter | Default | Purpose |\n|-----------|---------|---------|\n| `temperature` | 0.7 | Randomness (0=deterministic, 2=very random) |\n| `max_tokens` | Model max | Limit output length |\n| `parallel_tool_calls` | True | Execute multiple tools simultaneously |\n| `tool_choice` | \"auto\" | Force/prevent tool usage |\n| `top_p` | 1.0 | Alternative to temperature |\n\n### When to Adjust\n- **Lower temperature (0-0.3)**: Math, code, analysis\n- **Higher temperature (0.8-1.5)**: Creative writing, brainstorming\n- **Disable parallel tools**: When tools must run sequentially\n- **Force tool choice**: When agent must use specific tool",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "6c85edcb",
   "metadata": {},
   "source": "# Introduction to AI Agents using OpenAI Agents SDK\n## Complete Guide to GPT-5.2 & GPT-4o Agents (2026 Edition)\n\n> ‚ö†Ô∏è **COST WARNING**\n> - **WebSearchTool**: $0.025 per call\n> - **GPT-5.2 Instant/Thinking**: $1.75/1M input, $14/1M output\n> - **GPT-5.2 Pro**: $21/1M input, $168/1M output  \n> - **GPT-5.2-Codex**: $2.5/1M input, $20/1M output\n> - **GPT-4o (Alternative)**: ~$2.5/1M input, $10/1M output\n> - **Estimated total lab cost**: $3-$5\n\n## Prerequisites\n\nBefore starting, ensure you have:\n- ‚úÖ OpenAI API key with credits\n- ‚úÖ Python 3.10+\n- ‚úÖ Required packages: `openai>=1.54.0`, `agents`, `python-dotenv`, `pydantic>=2.0`\n\n## What You'll Learn\n\nThis comprehensive notebook covers:\n1. **Foundation**: GPT-5.2 models, cost tracking, environment setup\n2. **Basics**: Simple agents, model comparison, instructions\n3. **Tools**: Custom function tools, WebSearchTool, orchestration\n4. **Structured Outputs**: Pydantic models, validation, patterns\n5. **Multi-Agent Systems**: Handoffs, debates, orchestration\n6. **Advanced Features**: Streaming, parallel execution, Pro features\n7. **Real-World Use Cases**: RAG, data analysis, content pipelines\n8. **Production Patterns**: Error handling, testing, optimization\n\n## Installation\n\n```bash\npip install openai>=1.54.0 agents python-dotenv pydantic\n```\n\n## Setup .env File\n\nCreate a `.env` file in your project root:\n```\nOPENAI_API_KEY=your_openai_api_key_here\n```\n\n---\n\n**üìò Let's get started!**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c2688d",
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom dotenv import load_dotenv\nfrom agents import Agent, WebSearchTool, FileSearchTool, trace, Runner, function_tool\nfrom agents.model_settings import ModelSettings\nfrom IPython.display import display, Markdown, HTML, JSON\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List, Dict\nimport asyncio\nimport json\nfrom datetime import datetime\nimport time\n\n# Load environment variables\nload_dotenv()\nopenai_api_key = os.getenv(\"OPENAI_API_KEY\")\n\nif not openai_api_key:\n    raise ValueError(\"‚ùå OPENAI_API_KEY not found in environment\")\n\nprint(\"‚úÖ API key loaded successfully\")\n\n# Cost tracking class for GPT-5.2 and GPT-4o\nclass CostTracker:\n    \"\"\"Track API costs for GPT-5.2 and GPT-4o models\"\"\"\n    \n    PRICING = {\n        # GPT-5.2 models\n        \"gpt-5.2-chat-latest\": {\"input\": 1.75/1_000_000, \"output\": 14/1_000_000},\n        \"gpt-5.2\": {\"input\": 1.75/1_000_000, \"output\": 14/1_000_000},\n        \"gpt-5.2-pro\": {\"input\": 21/1_000_000, \"output\": 168/1_000_000},\n        \"gpt-5.2-codex\": {\"input\": 2.5/1_000_000, \"output\": 20/1_000_000},\n        # GPT-4o as alternative\n        \"gpt-4o\": {\"input\": 2.5/1_000_000, \"output\": 10/1_000_000},\n        \"gpt-4o-mini\": {\"input\": 0.15/1_000_000, \"output\": 0.6/1_000_000},\n    }\n    \n    def __init__(self):\n        self.calls = []\n        self.total_cost = 0\n        self.web_searches = 0\n    \n    def add_call(self, model: str, input_tokens: int, output_tokens: int):\n        \"\"\"Track an API call\"\"\"\n        pricing = self.PRICING.get(model, self.PRICING[\"gpt-4o\"])\n        cost = (input_tokens * pricing[\"input\"]) + (output_tokens * pricing[\"output\"])\n        \n        self.calls.append({\n            \"model\": model,\n            \"input_tokens\": input_tokens,\n            \"output_tokens\": output_tokens,\n            \"cost\": cost,\n            \"timestamp\": datetime.now()\n        })\n        self.total_cost += cost\n    \n    def add_web_search(self, count: int = 1):\n        \"\"\"Track web search costs\"\"\"\n        self.web_searches += count\n        self.total_cost += (count * 0.025)\n    \n    def report(self):\n        \"\"\"Display cost summary\"\"\"\n        print(f\"\\n{'='*60}\")\n        print(\"üí∞ COST SUMMARY\")\n        print(f\"{'='*60}\")\n        print(f\"Total API calls: {len(self.calls)}\")\n        print(f\"Web searches: {self.web_searches}\")\n        print(f\"Total cost: ${self.total_cost:.4f}\")\n        \n        if self.calls:\n            by_model = {}\n            for call in self.calls:\n                model = call[\"model\"]\n                by_model[model] = by_model.get(model, 0) + call[\"cost\"]\n            \n            print(\"\\nBy model:\")\n            for model, cost in by_model.items():\n                print(f\"  {model}: ${cost:.4f}\")\n        \n        print(f\"{'='*60}\\n\")\n\ntracker = CostTracker()\nprint(\"üìä Cost tracker initialized\")"
  },
  {
   "cell_type": "markdown",
   "id": "6d9fc1b2",
   "metadata": {},
   "source": "## üìç PHASE 1: Foundation & Setup\n\n## GPT-5.2 Model Family (Released December 2025)\n\n| Model | API ID | Best For | Speed | Input Cost | Output Cost |\n|-------|--------|----------|-------|------------|-------------|\n| **Instant** | `gpt-5.2-chat-latest` | Fast everyday tasks, simple queries | ‚ö°‚ö°‚ö° | $1.75/1M | $14/1M |\n| **Thinking** | `gpt-5.2` | Complex reasoning, analysis, coding | ‚ö°‚ö° | $1.75/1M | $14/1M |\n| **Pro** | `gpt-5.2-pro` | Maximum quality, hardest problems | ‚ö° | $21/1M | $168/1M |\n| **Codex** | `gpt-5.2-codex` | Agentic coding workflows | ‚ö°‚ö° | $2.5/1M | $20/1M |\n\n### GPT-4o as Alternative\n\n| Model | API ID | Best For | Speed | Input Cost | Output Cost |\n|-------|--------|----------|-------|------------|-------------|\n| **GPT-4o** | `gpt-4o` | General purpose, multimodal | ‚ö°‚ö° | $2.5/1M | $10/1M |\n| **GPT-4o-mini** | `gpt-4o-mini` | Fast, cost-effective | ‚ö°‚ö°‚ö° | $0.15/1M | $0.6/1M |\n\n---\n\n### When to Use Each Model\n\n**GPT-5.2 Instant** (`gpt-5.2-chat-latest`)\n- ‚úÖ Quick Q&A, translations, summaries\n- ‚úÖ High-volume simple requests  \n- ‚úÖ Fast classification tasks\n- üéØ **Performance**: Fastest response times\n\n**GPT-5.2 Thinking** (`gpt-5.2`)\n- ‚úÖ Complex analysis and reasoning\n- ‚úÖ Code generation and debugging\n- ‚úÖ Research and synthesis\n- ‚úÖ Multi-step problem solving\n- üéØ **Performance**: 30% fewer errors vs GPT-5.1\n\n**GPT-5.2 Pro** (`gpt-5.2-pro`)\n- ‚úÖ Advanced mathematics\n- ‚úÖ Scientific research\n- ‚úÖ Critical decision-making\n- ‚úÖ Maximum quality requirements\n- üéØ **Performance**: 93.2% GPQA Diamond, 100% AIME 2025\n\n**GPT-5.2-Codex** (`gpt-5.2-codex`)\n- ‚úÖ Terminal automation\n- ‚úÖ Multi-file code changes\n- ‚úÖ Complex refactoring\n- üéØ **Performance**: 56.4% SWE-Bench Pro, 64% Terminal-Bench\n\n**GPT-4o (Alternative)**\n- ‚úÖ Use when GPT-5.2 unavailable\n- ‚úÖ Similar capabilities to GPT-5.2 Thinking\n- ‚úÖ Lower cost than GPT-5.2\n- üéØ **Cost-effective alternative**"
  },
  {
   "cell_type": "code",
   "id": "ws1bv8skwl",
   "source": "def recommend_model(task_description: str) -> tuple[str, str]:\n    \"\"\"Recommend optimal model for a task (GPT-5.2 or GPT-4o fallback)\"\"\"\n    \n    task_lower = task_description.lower()\n    \n    # Pro indicators\n    if any(kw in task_lower for kw in [\"critical\", \"research\", \"mathematics\", \"prove\", \"scientific\"]):\n        return \"gpt-5.2-pro\", \"üèÜ Maximum quality for critical work (or gpt-4o if unavailable)\"\n    \n    # Codex indicators  \n    if any(kw in task_lower for kw in [\"code\", \"programming\", \"debug\", \"refactor\", \"terminal\"]):\n        return \"gpt-5.2-codex\", \"üíª Optimized for coding (or gpt-4o if unavailable)\"\n    \n    # Thinking indicators\n    if any(kw in task_lower for kw in [\"analyze\", \"plan\", \"reasoning\", \"complex\", \"multi-step\"]):\n        return \"gpt-5.2\", \"üß† Best for reasoning (or gpt-4o if unavailable)\"\n    \n    # Default to Instant\n    return \"gpt-5.2-chat-latest\", \"‚ö° Fast for simple tasks (or gpt-4o-mini if unavailable)\"\n\n# Test recommendations\nprint(\"üéØ Model Recommendation Examples:\\n\")\n\ntasks = [\n    \"Translate this text to Spanish\",\n    \"Analyze this 50-page research paper\",\n    \"Solve this advanced calculus problem\",\n    \"Debug my Python code\",\n    \"Quick FAQ answer\"\n]\n\nfor task in tasks:\n    model, reason = recommend_model(task)\n    print(f\"Task: {task}\")\n    print(f\"  ‚Üí Recommended: {model}\")\n    print(f\"  ‚Üí {reason}\\n\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "mg01v8ymu8s",
   "source": "## What is an AI Agent?\n\nAn **Agent** is an autonomous entity that can:\n1. üìù Receive instructions (system prompt)\n2. üõ†Ô∏è Use tools to gather information\n3. üß† Reason about tasks\n4. ‚úÖ Take actions to complete objectives\n\n### Agent Components\n\n```python\nAgent(\n    name=\"AgentName\",            # Identifier for tracking\n    instructions=\"What to do\",   # System prompt defining behavior\n    model=\"gpt-5.2\",            # Which model to use\n    tools=[...],                # Available functions (optional)\n    output_type=Schema,         # Structured response (optional)\n    model_settings=Settings,    # Temperature, etc. (optional)\n    handoff_to=[...]           # Other agents (optional)\n)\n```\n\n### Agent Execution Flow\n\n```\nUser Input\n    ‚Üì\nAgent Receives Task\n    ‚Üì\nProcesses with Instructions\n    ‚Üì\nCalls Tools (if needed)\n    ‚Üì\nReturns Response\n    ‚Üì\nLogged to Trace\n```\n\n### Key Concepts\n\n- **Tools**: Functions the agent can call (WebSearch, custom functions)\n- **Structured Outputs**: Typed responses using Pydantic models\n- **Handoffs**: Transferring to other specialized agents\n- **Traces**: Execution logs in OpenAI console\n- **Model Settings**: Temperature, token limits, tool choice\n\n### Model Selection\n\n- Use `gpt-5.2-chat-latest` (Instant) for simple, fast tasks\n- Use `gpt-5.2` (Thinking) for complex reasoning\n- Use `gpt-5.2-pro` (Pro) for maximum quality\n- Use `gpt-4o` as cost-effective alternative",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "xwt4hoe50hp",
   "source": "## Model Performance Benchmarks\n\n### GPT-5.2 Pro Benchmarks\n- üìä **GPQA Diamond**: 93.2%\n- üìä **AIME 2025**: 100%\n- üìä **SWE-Bench Verified**: 80%\n\n### GPT-5.2 Thinking\n- üìä **30% fewer errors** than GPT-5.1 Thinking\n- üìä **70.9% better** than top professionals on GDP\n\nval tasks\n\n### GPT-5.2-Codex\n- üìä **SWE-Bench Pro**: 56.4%\n- üìä **Terminal-Bench 2.0**: 64.0%\n\n### Context & Output\n- **Context window**: 400K tokens\n- **Max output**: 128K tokens\n- **Knowledge cutoff**: August 2025",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3a0s2z1kiqm",
   "source": "# Basic cost estimation examples\n\ndef estimate_cost(model: str, input_tokens: int, output_tokens: int) -> float:\n    \"\"\"Estimate cost for a given model and token usage\"\"\"\n    pricing = CostTracker.PRICING.get(model, CostTracker.PRICING[\"gpt-4o\"])\n    return (input_tokens * pricing[\"input\"]) + (output_tokens * pricing[\"output\"])\n\nprint(\"üí∞ Cost Estimation Examples\\n\")\nprint(\"=\"*70)\n\n# Example scenarios\nscenarios = [\n    (\"Simple query\", \"gpt-5.2-chat-latest\", 100, 200),\n    (\"Complex analysis\", \"gpt-5.2\", 500, 1000),\n    (\"Critical research\", \"gpt-5.2-pro\", 1000, 2000),\n    (\"Code generation\", \"gpt-5.2-codex\", 800, 1500),\n    (\"GPT-4o alternative\", \"gpt-4o\", 500, 1000),\n]\n\nfor desc, model, input_tok, output_tok in scenarios:\n    cost = estimate_cost(model, input_tok, output_tok)\n    print(f\"\\n{desc}:\")\n    print(f\"  Model: {model}\")\n    print(f\"  Tokens: {input_tok} in / {output_tok} out\")\n    print(f\"  Cost: ${cost:.4f}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(f\"\\nüí° Tip: Use tracker.add_call() after each agent run to track actual costs\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5ljm5wcv45f",
   "source": "## Understanding Traces & Debugging\n\n**Traces** are execution logs that help you debug and understand agent behavior.\n\n### What Gets Logged\n- üìù Agent instructions and model used\n- üîÑ Complete message history\n- üõ†Ô∏è Tool calls and responses\n- ‚è±Ô∏è Timing and performance metrics\n- üí∞ Token usage\n\n### Viewing Traces\nAll traces are automatically logged to:\n**https://platform.openai.com/traces**\n\n### Using Traces\n\n```python\n# Create named trace\nwith trace(\"My Task Description\"):\n    result = await Runner.run(agent, \"query\")\n\n# Generate custom trace ID\ntrace_id = gen_trace_id()\nwith trace(\"Task\", trace_id=trace_id):\n    result = await Runner.run(agent, \"query\")\n```\n\n### Benefits\n- ‚úÖ Debug agent behavior\n- ‚úÖ Monitor performance\n- ‚úÖ Track costs\n- ‚úÖ Optimize prompts\n- ‚úÖ Share with team",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "msy4q0qwrun",
   "source": "# Trace ID generation and organization examples\n\nfrom agents import gen_trace_id\n\nprint(\"üîç Trace Organization Examples\\n\")\nprint(\"=\"*70)\n\n# Generate custom trace IDs\ntrace_ids = {\n    \"simple_query\": gen_trace_id(),\n    \"complex_analysis\": gen_trace_id(),\n    \"multi_step_task\": gen_trace_id()\n}\n\nprint(\"\\nüìã Generated Trace IDs:\")\nfor task_name, tid in trace_ids.items():\n    print(f\"  {task_name}: {tid}\")\n\nprint(\"\\nüí° Usage:\")\nprint(\"\"\"\n# Organized traces by task type\nwith trace(\"Simple Query\", trace_id=trace_ids['simple_query']):\n    result = await Runner.run(agent, \"What is 2+2?\")\n\n# All related traces will share same ID prefix\n# Easy to find and group in OpenAI console\n\"\"\")\n\nprint(\"=\"*70)\nprint(\"\\n‚úÖ Phase 1 setup complete! Ready for Phase 2.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "21u59gxm63k",
   "source": "## ‚úÖ Phase 1 Complete: Foundation & Setup\n\n### What You Learned\n- ‚úÖ GPT-5.2 model family (Instant, Thinking, Pro, Codex)\n- ‚úÖ GPT-4o as cost-effective alternative\n- ‚úÖ Cost tracking with CostTracker class\n- ‚úÖ Model selection for different tasks\n- ‚úÖ Agent fundamentals and components\n- ‚úÖ Performance benchmarks\n- ‚úÖ Trace logging and debugging\n\n### Key Takeaways\n1. **Model Selection**: Use Instant for speed, Thinking for reasoning, Pro for quality\n2. **Cost Management**: Track costs with `tracker.add_call()`\n3. **Debugging**: Use traces to understand agent behavior\n4. **Alternatives**: GPT-4o available when GPT-5.2 unavailable\n\n### Next Up: Phase 2 - Basic Agents\nIn the next phase, you'll learn to:\n- Create your first AI agent\n- Compare models live\n- Engineer effective instructions\n- Control temperature and creativity\n\n---\n\n**Ready to build your first agent?** ‚Üí Continue to Phase 2!",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "gmf3b0dc4or",
   "source": "## üìç PHASE 2: Basic Agents\n\nIn this phase, you'll create your first AI agents and learn how to:\n- Run agents with different models\n- Compare GPT-5.2 vs GPT-4o\n- Control creativity with temperature\n- Write effective instructions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05006ac",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 11: Your First Agent with GPT-5.2 or GPT-4o\n\n# Create a simple agent\nbasic_agent = Agent(\n    name=\"QuickResponder\",\n    instructions=\"Answer questions concisely in Singlish style\",\n    model=\"gpt-4o\"  # Use gpt-4o (or gpt-5.2-chat-latest if available)\n)\n\n# Run the agent\nwith trace(\"First Agent Run\"):\n    result = await Runner.run(basic_agent, \"Tell me a joke about AI agents lah\")\n    print(\"ü§ñ Agent Response:\")\n    print(result.final_output)\n\n# Track cost (estimate)\ntracker.add_call(\"gpt-4o\", 50, 150)\nprint(\"\\n\" + \"=\"*60)\nprint(\"‚úÖ Your first agent ran successfully!\")\nprint(\"üí° Check traces at: https://platform.openai.com/traces\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9239bc",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 12: Live Model Comparison (GPT-4o vs GPT-5.2)\n\nprint(\"üî¨ Comparing GPT-4o and GPT-5.2 (if available)\\n\")\nprint(\"=\"*70)\n\ntask = \"Explain how AI agents work in 2 sentences\"\n\n# Test GPT-4o\ngpt4o_agent = Agent(\n    name=\"GPT4o-Agent\",\n    instructions=\"Explain clearly and concisely\",\n    model=\"gpt-4o\"\n)\n\nprint(\"\\n**GPT-4o Response:**\")\nwith trace(\"GPT-4o Test\"):\n    result_4o = await Runner.run(gpt4o_agent, task)\n    print(result_4o.final_output)\ntracker.add_call(\"gpt-4o\", 80, 100)\n\n# Optionally test GPT-5.2 if available\n# Uncomment if you have GPT-5.2 access:\n# print(\"\\n**GPT-5.2 Response:**\")\n# gpt52_agent = Agent(\n#     name=\"GPT52-Agent\", \n#     instructions=\"Explain clearly and concisely\",\n#     model=\"gpt-5.2-chat-latest\"\n# )\n# with trace(\"GPT-5.2 Test\"):\n#     result_52 = await Runner.run(gpt52_agent, task)\n#     print(result_52.final_output)\n# tracker.add_call(\"gpt-5.2-chat-latest\", 80, 100)\n\nprint(\"\\n\" + \"=\"*70)\ntracker.report()"
  },
  {
   "cell_type": "markdown",
   "id": "dwj2lbmbzef",
   "source": "## Temperature & Creativity Control\n\n**Temperature** controls the randomness/creativity of agent responses:\n- **0.0**: Deterministic, consistent, factual\n- **0.7**: Balanced (default)\n- **1.0+**: More creative, varied, unpredictable\n\n### When to Use Different Temperatures\n\n| Temperature | Best For | Example Use Case |\n|-------------|----------|------------------|\n| 0.0 - 0.3 | Facts, analysis, code | Math problems, data analysis |\n| 0.4 - 0.7 | General purpose | Q&A, instructions |\n| 0.8 - 1.2 | Creative content | Stories, marketing copy |\n| 1.3 - 2.0 | High creativity | Brainstorming, art |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "8m1nrywgum5",
   "source": "# Cell 14: Temperature Comparison Demo\n\nprint(\"üå°Ô∏è Temperature Comparison\\n\")\nprint(\"=\"*70)\n\ntask = \"Write a one-sentence story opening about robots\"\n\ntemperatures = [0.0, 0.7, 1.5]\n\nfor temp in temperatures:\n    print(f\"\\n**Temperature {temp}:**\")\n    \n    agent = Agent(\n        name=f\"Agent-temp-{temp}\",\n        instructions=\"Write creative story openings\",\n        model=\"gpt-4o\",\n        model_settings=ModelSettings(temperature=temp)\n    )\n    \n    with trace(f\"Temp {temp}\"):\n        result = await Runner.run(agent, task)\n        print(result.final_output)\n    \n    tracker.add_call(\"gpt-4o\", 50, 80)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"\\nüí° Notice: Higher temperature = more creative/varied responses\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8t30udlapnn",
   "source": "## Instruction Engineering Best Practices\n\nGood instructions are the foundation of effective agents. Follow these principles:\n\n### ‚úÖ Good Instructions\n- **Specific**: Define exact behavior and output format\n- **Clear**: Use simple, unambiguous language\n- **Complete**: Include all necessary context\n- **Structured**: Use numbered steps or bullet points\n- **Examples**: Show desired output format\n\n### ‚ùå Bad Instructions\n- Vague: \"Help the user\"\n- Ambiguous: \"Be creative\"\n- Incomplete: Missing key context\n- Unstructured: Wall of text\n\n### Template\n```\nYou are a [ROLE].\n\nYour task:\n1. [Step 1]\n2. [Step 2]\n3. [Step 3]\n\nOutput format: [FORMAT]\n\nExample:\n[EXAMPLE]\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "no4kjh8lzi",
   "source": "# Cell 16: Good vs Bad Instructions Demo\n\nprint(\"üìù Instruction Quality Comparison\\n\")\nprint(\"=\"*70)\n\ntask = \"Summarize this: 'AI agents are autonomous software that can use tools and make decisions.'\"\n\n# ‚ùå Bad: Vague instructions\nbad_agent = Agent(\n    name=\"VagueAgent\",\n    instructions=\"Help summarize things\",\n    model=\"gpt-4o\"\n)\n\nprint(\"\\n‚ùå **Bad Instructions** ('Help summarize things'):\")\nresult_bad = await Runner.run(bad_agent, task)\nprint(result_bad.final_output)\n\n# ‚úÖ Good: Specific instructions\ngood_agent = Agent(\n    name=\"SpecificAgent\",\n    instructions=\"\"\"You are a summarization expert.\n\nTask: Summarize text in exactly 1 sentence, max 15 words.\nStyle: Simple, clear language.\nFormat: Single sentence, no preamble.\"\"\",\n    model=\"gpt-4o\"\n)\n\nprint(\"\\n‚úÖ **Good Instructions** (Specific, structured):\")\nresult_good = await Runner.run(good_agent, task)\nprint(result_good.final_output)\n\nprint(\"\\n\" + \"=\"*70)\ntracker.add_call(\"gpt-4o\", 100, 100)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "m1gbptpn3lg",
   "source": "## ‚úÖ Phase 2 Complete: Basic Agents\n\n### What You Learned\n- ‚úÖ Created first runnable agents with GPT-4o\n- ‚úÖ Compared different models\n- ‚úÖ Controlled creativity with temperature\n- ‚úÖ Engineered effective instructions\n- ‚úÖ Good vs bad instruction patterns\n\n### Key Takeaways\n1. **Temperature**: 0.0 for facts, 0.7 for balance, 1.5+ for creativity\n2. **Instructions**: Specific > Vague, Structured > Unstructured\n3. **Model Choice**: GPT-4o for general use, GPT-5.2 when available\n4. **Traces**: Always use `with trace()` for debugging\n\n### Next Up: Phase 3 - Custom Tools\nLearn to create and use custom function tools to extend agent capabilities!\n\n---\n\n**Ready for Phase 3?** ‚Üí Continue below!",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "26w5tzseh68",
   "source": "## üìç PHASE 3: Custom Tools\n\nTools extend agent capabilities by giving them access to functions. In this phase, you'll learn:\n- Creating custom tools with `@function_tool`\n- Using WebSearchTool for web research\n- Tool parameter validation\n- Multiple tool orchestration",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "xeraftqwjjj",
   "source": "# Cell 22: Creating Custom Function Tools\n\n@function_tool\ndef calculate_cost(input_tokens: int, output_tokens: int, model: str = \"gpt-4o\") -> str:\n    \"\"\"Calculate exact API cost for given model and token usage\"\"\"\n    pricing = CostTracker.PRICING.get(model, CostTracker.PRICING[\"gpt-4o\"])\n    cost = (input_tokens * pricing[\"input\"]) + (output_tokens * pricing[\"output\"])\n    return f\"üí∞ Cost for {model}: ${cost:.6f} ({input_tokens} in + {output_tokens} out tokens)\"\n\n@function_tool\ndef get_current_time() -> str:\n    \"\"\"Get current date and time\"\"\"\n    return f\"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n\n@function_tool\ndef word_count(text: str) -> str:\n    \"\"\"Count words in text\"\"\"\n    count = len(text.split())\n    return f\"üìä Word count: {count}\"\n\nprint(\"‚úÖ Created 3 custom function tools:\")\nprint(\"  1. calculate_cost() - Estimates API costs\")\nprint(\"  2. get_current_time() - Returns current datetime\")\nprint(\"  3. word_count() - Counts words in text\")\nprint(\"\\nüí° These tools can now be used by agents!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ad5xmq4s4g",
   "source": "# Cell 23: Agent Using Custom Tools\n\ntool_agent = Agent(\n    name=\"ToolUser\",\n    instructions=\"You help users by calling the appropriate tools. Always use tools to get accurate information.\",\n    model=\"gpt-4o\",\n    tools=[calculate_cost, get_current_time, word_count],\n    model_settings=ModelSettings(tool_choice=\"required\")  # Force tool use\n)\n\nprint(\"ü§ñ Agent with Custom Tools\\n\")\nprint(\"=\"*70)\n\nqueries = [\n    \"What time is it now?\",\n    \"How many words are in 'AI agents are transforming software development'?\",\n    \"Calculate cost for 1000 input and 500 output tokens using gpt-4o\"\n]\n\nfor query in queries:\n    print(f\"\\n‚ùì Query: {query}\")\n    with trace(f\"Tool Query\"):\n        result = await Runner.run(tool_agent, query)\n        print(f\"üí¨ Response: {result.final_output}\")\n    tracker.add_call(\"gpt-4o\", 100, 150)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ Agent successfully used custom tools!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "881facb9",
   "metadata": {},
   "source": [
    "You can check what the AI agent in Traces within the Open AI Console: \n",
    "https://platform.openai.com/logs?api=traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5b89dd",
   "metadata": {},
   "source": "## WebSearchTool Deep Dive\n\n**WebSearchTool** is a hosted tool that lets agents search the web for current information.\n\n### OpenAI Hosted Tools\n- **WebSearchTool**: Search the web ($0.025 per call)\n- **FileSearchTool**: Query Vector Stores\n- **ComputerTool**: Automate computer tasks\n\n### WebSearchTool Configuration\n\n```python\nWebSearchTool(\n    search_context_size=\"low\"    # low, medium, high\n)\n```\n\n| Context Size | Cost | Use When |\n|--------------|------|----------|\n| **low** | $ | Simple facts |\n| **medium** | $$ | Detailed research |\n| **high** | $$$ | Comprehensive analysis |\n\n### Important: Cost Warning\n- **$0.025 per search call**\n- Can add up quickly ($2-$3 for this lab)\n- Use `tracker.add_web_search()` to monitor\n\n### Best Practices\n1. Use `tool_choice=\"required\"` to ensure web search\n2. Start with \"low\" context size\n3. Track costs with `tracker.add_web_search()`\n4. Combine multiple queries when possible"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51717c9a",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 25: Web Search Agent with GPT-4o\n\nSEARCH_INSTRUCTIONS = \"\"\"You are a research assistant. Search the web and provide:\n1. Brief summary (2-3 sentences)\n2. Key findings (3-4 bullet points)\n3. Source information\n\nBe concise and factual.\"\"\"\n\nsearch_agent = Agent(\n    name=\"SearchAgent\",\n    instructions=SEARCH_INSTRUCTIONS,\n    tools=[WebSearchTool(search_context_size=\"low\")],\n    model=\"gpt-4o\",  # Or gpt-5.2 if available\n    model_settings=ModelSettings(tool_choice=\"required\")\n)\n\n# Execute search\nprint(\"üîç Web Search Demo\\n\")\nprint(\"=\"*70)\n\nquery = \"Latest AI agent frameworks 2026\"\nprint(f\"\\nSearching: {query}\\n\")\n\nwith trace(\"Web Search\"):\n    result = await Runner.run(search_agent, query)\n    display(Markdown(result.final_output))\n\n# Track costs\ntracker.add_web_search(1)  # $0.025\ntracker.add_call(\"gpt-4o\", 300, 500)\n\nprint(\"\\n\" + \"=\"*70)\ntracker.report()"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "e9762fc9",
   "metadata": {},
   "outputs": [],
   "source": "## ‚úÖ Phase 3 Complete: Custom Tools\n\n### What You Learned\n- ‚úÖ Created custom tools with `@function_tool` decorator\n- ‚úÖ Used WebSearchTool for web research\n- ‚úÖ Forced tool usage with `tool_choice=\"required\"`\n- ‚úÖ Tracked web search costs\n- ‚úÖ Combined multiple tools in one agent\n\n### Key Takeaways\n1. **Custom Tools**: Use `@function_tool` for any Python function\n2. **WebSearchTool**: Costs $0.025 per call - track carefully\n3. **Tool Choice**: `required` forces tool use, `auto` lets agent decide\n4. **Best Practice**: Always track costs with `tracker`\n\n### Tool Types\n- **Custom**: Your Python functions\n- **Hosted**: WebSearchTool, FileSearchTool, ComputerTool\n- **Future**: Build complex tool ecosystems\n\n### Next Up: Phase 4 - Structured Outputs\nLearn to get typed, validated responses using Pydantic models!\n\n---\n\n**Ready for Phase 4?** ‚Üí Continue below!"
  },
  {
   "cell_type": "markdown",
   "id": "7605c27a",
   "metadata": {},
   "source": "## üìç PHASE 4: Structured Outputs\n\n**Structured Outputs** use Pydantic models to get typed, validated responses instead of free-form text.\n\n### Why Structured Outputs?\n- ‚úÖ **Type-safe**: Guaranteed data types\n- ‚úÖ **Validated**: Automatic validation\n- ‚úÖ **Parseable**: Easy to use programmatically\n- ‚úÖ **Self-documenting**: Schema describes expected output\n\n### How It Works\n\n```python\n# 1. Define Pydantic model\nclass MyOutput(BaseModel):\n    field1: str = Field(description=\"What this field is\")\n    field2: int = Field(description=\"Another field\")\n\n# 2. Use as output_type\nagent = Agent(\n    model=\"gpt-4o\",\n    output_type=MyOutput  # Agent must return this structure\n)\n\n# 3. Get typed response\nresult = await Runner.run(agent, \"query\")\noutput = result.final_output  # MyOutput instance\n```\n\n### Use Cases\n- Research reports\n- Data extraction\n- Classification\n- Multi-step plans\n- Structured analysis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3dc37",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 37: Basic Structured Output Example\n\n# Define output schema\nclass ResearchPlan(BaseModel):\n    topic: str = Field(description=\"Research topic\")\n    searches: List[str] = Field(description=\"3-5 web search queries to perform\")\n    approach: str = Field(description=\"Research strategy\")\n    estimated_time: str = Field(description=\"Estimated time needed\")\n\n# Create agent with structured output\nplanner_agent = Agent(\n    name=\"ResearchPlanner\",\n    instructions=\"Create detailed research plans. Be specific with search queries.\",\n    model=\"gpt-4o\",\n    output_type=ResearchPlan  # Forces this structure\n)\n\n# Run agent\nprint(\"üìã Structured Output Demo\\n\")\nprint(\"=\"*70)\n\ntopic = \"AI Agent security best practices\"\nprint(f\"\\nPlanning research for: {topic}\\n\")\n\nwith trace(\"Research Planning\"):\n    result = await Runner.run(planner_agent, f\"Create research plan for: {topic}\")\n    plan = result.final_output  # ResearchPlan instance\n\n# Access typed fields\nprint(f\"**Topic**: {plan.topic}\")\nprint(f\"**Approach**: {plan.approach}\")\nprint(f\"**Estimated Time**: {plan.estimated_time}\")\nprint(f\"\\n**Search Queries**:\")\nfor i, query in enumerate(plan.searches, 1):\n    print(f\"  {i}. {query}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ Got validated, typed output!\")\n\ntracker.add_call(\"gpt-4o\", 200, 300)"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "307c6f60",
   "metadata": {},
   "outputs": [],
   "source": "## ‚úÖ Phase 4 Complete: Structured Outputs\n\n### What You Learned\n- ‚úÖ Created Pydantic models for typed outputs\n- ‚úÖ Used `output_type` parameter\n- ‚úÖ Accessed validated, typed fields\n- ‚úÖ Built research planning agent\n\n### Key Takeaways\n1. **Pydantic Models**: Define expected structure with `BaseModel`\n2. **Field Descriptions**: Help the model understand schema\n3. **Type Safety**: Guaranteed data types (str, int, List, etc.)\n4. **Validation**: Automatic checking of required fields\n\n### Pattern\n```python\nclass MySchema(BaseModel):\n    field: str = Field(description=\"Clear description\")\n\nagent = Agent(output_type=MySchema, ...)\nresult = await Runner.run(agent, \"...\")\ntyped_output = result.final_output  # MySchema instance\n```\n\n---\n\n## üéâ Phases 1-4 Complete!\n\nYou've built a strong foundation:\n- ‚úÖ Cost tracking and model selection\n- ‚úÖ Basic agents with instructions\n- ‚úÖ Custom tools and WebSearch\n- ‚úÖ Structured, validated outputs\n\n### Next Steps\nThe remaining phases cover advanced topics:\n- **Phase 5**: Multi-agent systems (handoffs, debates)\n- **Phase 6**: Advanced features (streaming, parallel execution)\n- **Phase 7**: Real-world use cases (RAG, content pipelines)\n- **Phases 8-10**: Production patterns, testing, best practices\n\n**üìù Note**: This is a natural checkpoint to save your progress!\n\n---\n\n**Want to continue? Scroll down for advanced phases!**"
  },
  {
   "cell_type": "markdown",
   "id": "mmiknda9mv",
   "source": "## üìç PHASE 5: Multi-Agent Systems\n\nMulti-agent systems use multiple specialized agents working together to solve complex problems.\n\n### Patterns\n1. **Handoffs (Triage)**: Router delegates to specialists\n2. **Debate**: Agents argue different perspectives  \n3. **Orchestrator**: Manager coordinates workers\n4. **Parallel**: Multiple agents work simultaneously\n\n### Benefits\n- Specialization: Each agent expert in one domain\n- Scalability: Add agents as needed\n- Reliability: Redundancy and validation\n- Flexibility: Easy to modify behavior",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "4dp88dn7b4n",
   "source": "# Phase 5: Handoff Pattern Demo\n\n# Define specialist agents\ntechnical_agent = Agent(\n    name=\"TechnicalExpert\",\n    instructions=\"Answer technical questions about AI agents with code examples\",\n    model=\"gpt-4o\"\n)\n\nsupport_agent = Agent(\n    name=\"SupportAgent\", \n    instructions=\"Help with account and billing issues\",\n    model=\"gpt-4o\"\n)\n\n# Router with handoffs\nrouter_agent = Agent(\n    name=\"Router\",\n    instructions=\"\"\"Route queries to appropriate specialist:\n    - Technical questions ‚Üí TechnicalExpert\n    - Account/billing ‚Üí SupportAgent\n    - General questions ‚Üí answer directly\"\"\",\n    model=\"gpt-4o\",\n    handoff_to=[\"TechnicalExpert\", \"SupportAgent\"]\n)\n\nprint(\"üîÄ Multi-Agent Handoff Demo\\n\")\nprint(\"=\"*70)\n\nqueries = [\n    \"How do I create a custom tool?\",\n    \"I can't access my account\",\n    \"What is an AI agent?\"\n]\n\nfor query in queries:\n    print(f\"\\n‚ùì Query: {query}\")\n    with trace(f\"Handoff: {query[:30]}\"):\n        result = await Runner.run(router_agent, query)\n        print(f\"üí¨ Response: {result.final_output[:200]}...\")\n    tracker.add_call(\"gpt-4o\", 150, 250)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ Router successfully delegated to specialists!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4ewutdoz4h3",
   "source": "## ‚úÖ Phase 5 Complete: Multi-Agent Systems\n\n### What You Learned\n- ‚úÖ Handoff pattern (triage/routing)\n- ‚úÖ Multi-agent coordination\n- ‚úÖ Specialist agent design\n- ‚úÖ Agent-to-agent communication\n\n### Key Patterns\n1. **Handoff**: `handoff_to=[\"Agent1\", \"Agent2\"]`\n2. **Debate**: Agents with opposing views\n3. **Orchestrator**: Manager + Workers\n4. **Parallel**: `asyncio.gather()` for simultaneous execution\n\n### Best Practices\n- Clear agent responsibilities\n- Avoid circular handoffs\n- Use appropriate models per agent\n- Track costs across all agents\n\n---\n\n## üìç PHASE 6: Advanced Features\n\nAdvanced capabilities for production-ready agents:\n- Streaming responses for real-time output\n- Parallel tool execution\n- Memory and context management\n- Advanced ModelSettings",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}